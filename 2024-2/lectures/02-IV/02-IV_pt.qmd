---
title: "Econometria III"
subtitle: "Variáveis Instrumentais"
title-slide-attributes:
  data-background-image: "img/UdescEsag.jpeg"
  data-background-size: 50%
  data-background-position: top left
  # data-background-opacity: "0.7"
center-title-slide: true
author: "Rafael Bressan"
logo: "img/UdescEsag.jpeg"
format: 
  revealjs:
    theme: [default, ../udesc.scss] 
    code-fold: true
    # chalkboard: true
    incremental: true
    width: 1600
    height: 900
    embed-resources: true
from: markdown+emoji # list of emojis: https://gist.github.com/rxaviers/7360908
fontsize: "2.2em"
# editor: source
jupyter: python3
---

```{python}
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
```

## Preparando a cena


* Nos capítulos [7](https://scpoecon.github.io/ScPoEconometrics/causality.html), [8](https://scpoecon.github.io/ScPoEconometrics/STAR.html) e [9](https ://scpoecon.github.io/ScPoEconometrics/RDD.html) do livro `Introduction to Econometrics with R` é falado sobre os méritos dos _métodos experimentais_.

* Experimentos aleatorizados (RCTs) ou configurações _Quasi-experimentais_ (tão bons quanto aleatórios) nos permitem estimar efeitos **causais**.

* Se as pessoas tiverem algum tipo de opção sobre a ingestão do tratamento, haverá *seleção*.

* RCTs podem quebrar a auto-seleção de pessoas em tratamento, designando-as aleatoriamente.

* Então, com dados experimentais, temos uma boa solução.

* E os dados não experimentais?


## Dados não experimentais

::::{.columns}
:::{.column width="50%"}

* Falamos sobre **viés de variável omitida**.

* E se houver correlação entre uma variável no termo de erro $u$, $x_2$ digamos, e nossa variável explicativa $x_1$?

* Obteremos estimativas tendenciosas porque não podemos separar o que é o quê: efeito de $x_1$, ou de $x_2$?

* Lembre-se de que isso pode ser tão grave que nem conseguimos o sinal correto de um efeito.
:::

:::{.column width="50%"}

![](img/IV_ovb_dag.png)

:::
::::


<center>
- **VI** fornece uma solução para VVO.
</center>

## Endogeneidade

- Sempre que uma variável explicativa em uma regressão múltipla for **correlacionada com o termo de erro**, dizemos que esta variável é **endógena**

:::{.fragment}
$$
y=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k + \varepsilon
$$
:::

- $E[\varepsilon \mid x_1, \ldots x_k]\neq 0$

- Endogeneidade pode ocorrer por diversos motivos:
    + Forma funcional mal especificada
    + Omissão de variável relevante
    + Erro de medida nos regressores
    + Determinação simultânea entre variável dependente e independentes

## RCT Resolve Endogeneidade

- Considere uma especifcação linear para estimar o efeito causal de $x$ em $y$
$$y=\beta_0 +\beta_1 x + \varepsilon$$

- Com **dados observacionais** é fácil imaginar que omitimos diversas variáveis que ajudam a explicar $y$ e são correlacionadas com $x$. $E[\varepsilon\mid x]\neq 0$.
    + :warning: **Endogeneidade**

- Quando realizamos um experimento aleatorizado, $x$ passa a ser uma variável atribuída de forma **independente** de qualquer outro possível regressor omitido. $E[\varepsilon\mid x]=0$.
    + $x$ passou a ser um regressor **exógeno**
    + $\beta_1$ pode ser interpretado como efeito causal de $x$ em $y$

## Modelo de Transmissão do Cólera de Snow


* Suponha que $c_i$ assuma o valor 1 se o indivíduo $i$ morrer de cólera, 0 caso contrário.

* Seja $w_i = 1$ significando que o abastecimento de água de $i$ é impuro e $w_i = 0$ vice-versa. A pureza da água é avaliada com uma tecnologia que não detecta pequenos micróbios.

* Colete em $u_i$ todos os fatores não observáveis que afetam a probabilidade de $i$ morrer da doença: se $i$ é pobre, onde exatamente eles residem, se há má qualidade do ar nos arredores de $i$ e outras características individuais que impactam o resultado (como configuração genética de $i$).


:::{.fragment}
Nós podemos escrever:

$$
c_i = \alpha + \delta w_i + u_i
$$
:::


## Fazer o simples é sempre certo?

* John Snow poderia ter usado seus dados e avaliar a correlação entre beber água impura e a incidência de cólera.

* medida $Cor(c_i,w_i)$

* Suponha $Cor(c_i,w_i) \approx 0,5$. Isso prova a teoria da infecção?


- :warning: Não é bem assim. Angus Deaton disse:

:::{.fragment}
> As pessoas que bebiam água impura também eram mais propensas a serem pobres e a viver em um ambiente contaminado de várias maneiras, principalmente pelos “miasmas venenosos” que eram então considerados a causa da cólera.
:::


## A coisa simples


* Não faz sentido comparar alguém que bebe água pura com alguém que bebe água impura.

* porque *tudo o mais não é igual*: a água impura está correlacionada com ser pobre, morar em área ruim, má qualidade do ar e assim por diante - todos os fatores que encontramos em $u_i$.

* Isso viola a suposição crucial de ortogonalidade para estimativas MQO válidas, $E[u_i | w_i]=0$ neste contexto.

* Outra maneira de dizer isso é que $Cov(w_i, u_i) \neq 0$, implicando que $w_i$ é ***endógeno***.

* Existem fatores em $u_i$ que afetam tanto $w_i$ quanto $c_i$



## Modelo de Snow e um pouco de álgebra

Lembre-se do nosso modelo simples:
$$c_i = \alpha + \delta w_i + u_i$$

- Agora vamos condicionar os dois valores de $w$:
\begin{align}
E[c_i | w_i = 1] &= \alpha + \delta + E[u_i | w_i = 1] \\
E[c_i | w_i = 0] &= \alpha + \phantom{\delta} + E[u_i | w_i = 0]
\end{align}



- Agora subtraia uma linha da outra:
\begin{equation}
E[c_i | w_i = 1] - E[c_i | w_i = 0] = \delta + \left\{ E[u_i | w_i = 1] - E[u_i | w_i = 0]\right\}
\end{equation}

- O último termo $\left\{ E[u_i | w_i = 1] - E[u_i | w_i = 0]\right\}$ não é igual a zero (pelo que Deaton disse!)

- Uma estimativa de regressão para $\delta$ seria influenciada por essa quantidade.



## Estimador de Variáveis Instrumentais


* Snow propõe uma **variável instrumental** $z_i$, a *identidade da empresa fornecedora de água* para o domicílio $i$:

- Mais formalmente, vamos definir o instrumento da seguinte forma:

:::{.fragment}
\begin{align*}
z_i &= \begin{cases}
                     1 & \text{se água fornecida por Lambeth} \\
                     0 & \text{se água fornecida por Southwark ou Vauxhall.} \\
       \end{cases} \\
\end{align*}
:::

* $z_i$ está altamente correlacionado com a pureza da água $w_i$.

* No entanto, parece não ter correlação com todos os outros fatores em $u_i$, que nos preocupavam antes: o abastecimento de água foi decidido anos antes, e agora as casas na mesma rua têm fornecedores diferentes!

## VI em um DAG

![](img/IV-dag.png)


## Definindo a VI de Snow formalmente


Aqui estão as ***condições para um instrumento válido***:

1. **Relevância**: A pureza da água é, de fato, uma função da identidade do fornecedor. Queremos que $E[w_i | z_i = 1] \neq E[w_i | z_i = 0]$, ou seja, a pureza média da água difere entre os fornecedores. Podemos *verificar* esta condição com dados observacionais. 


2. **Independência**: Se uma família tem $z_i = 1$ ou $z_i = 0$ não tem relação com $u$, portanto $z$ é *tão bom quanto aleatório*. Se condicionarmos $u$ a certos valores de $z$ não altera o resultado - queremos $E[u_i | z_i = 1] = E[u_i | z_i = 0].$


3. **Exclusividade** o instrumento deve afetar o resultado $c$ *somente* através do canal especificado (ou seja, através da pureza da água $w$), e nada mais.


## Definindo o estimador de VI

- Agora estamos prontos para definir um estimador de VI simples. Como antes, vamos condicionar os valores de $z$:
\begin{align}
E[c_i | z_i = 1] &= \alpha + \delta E[w_i | z_i = 1] + E[u_i | z_i = 1] \\
E[c_i | z_i = 0] &= \alpha + \delta E[w_i | z_i = 0] + E[u_i | z_i = 0]
\end{align}

- tomando a diferença entre as expressões:
\begin{align}
E[c_i | z_i = 1] - E[c_i | z_i = 0] &= \delta \left\{ E[w_i | z_i = 1] - E[w_i | z_i = 0]\right\} \\
&+ \underbrace{\left\{ E[u_i | z_i = 1] - E[u_i | z_i = 0] \right\}}_{=0 \text{ por Indepedência}}
\end{align}


- Finalmente, se a VI for *relevante*, ou seja, $E[w_i | z_i = 1] - E[w_i | z_i = 0] \neq 0$:
\begin{equation}
\delta = \frac{E[c_i | z_i = 1] - E[c_i | z_i = 0]}{E[w_i | z_i = 1] - E[w_i | z_i = 0]}
\end{equation}




## Caso Especial: Estimador de Wald 

- Digamos que $x \mapsto y$ significa que $x$ é uma estimativa para $y$:

    1. $\overline{c}_1 \mapsto E[c_i | z_i = 1]$: a proporção de domicílios abastecidos por Lambeth com cólera.
    1. $\overline{w}_1 \mapsto E[w_i | z_i = 1]$: a proporção de domicílios abastecidos por Lambeth com água ruim.
    1. $\overline{c}_0 \mapsto E[c_i | z_i = 0]$: a proporção de domicílios não abastecidos por Lambeth com cólera.
    1. $\overline{w}_0 \mapsto E[w_i | z_i = 0]$: a proporção de domicílios não abastecidos por Lambeth com água ruim.

- O estimador seria então
\begin{equation}
\hat{\delta} = \frac{\overline{c}_1 - \overline{c}_0}{\overline{w}_1 - \overline{w}_0} 
\end{equation}

- Neste caso especial onde todas as variáveis envolvidas $c,w,z$ são binárias, o estimador é chamado de ***estimador de Wald***.

## Resumo

- VIs são uma ferramenta poderosa para estabelecer causalidade em contextos apenas com dados observacionais e onde estamos preocupados que a suposição de média condicional $E[u_i | x_i]=0$ é violado (*endogeneidade*). 

- As principais características da VI $z$ são que:

    1. $z$ é *relevante* para $x$. Por exemplo, em uma regressão simples de $z$ em $x$, queremos que $z$ tenha um poder preditivo considerável. Podemos *testar* essa condição nos dados.

    1. Precisamos de uma teoria segundo a qual seja *razoável* supor que $z$ não esteja *relacionado* a outros fatores não observáveis que possam impactar o resultado. Portanto, $z$ é *exógeno* a $u$, ou $E[u | z] = 0$. Esta é uma **suposição** (ou seja, não podemos testar isso com dados).


## Aplicações de Variáveis Instrumentais 

- O que fizemos na aula passada?

    + Aprendemos sobre o grande experimento de John Snow em Londres em 1850.

    + Usamos sua história para motivar o estimador IV.

- Hoje

    * Veremos outras aplicações IV.

    * Introduzimos uma extensão chamada ***Mínimos Quadrados em 2 Estágios***.

    * Usaremos `Python` para calcular as estimativas.

    * Finalmente falaremos sobre instrumentos *fracos*.



## Retornos da Escolaridade

::::{.columns}
:::{.column width="50%"}

* Qual é o impacto causal da escolaridade sobre os rendimentos?

* [Jacob Mincer](https://en.wikipedia.org/wiki/Jacob_Mincer) estava interessado nesta importante questão.

* Aqui está o modelo dele:
$$
\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + e_i
$$
:::


:::{.column width="50%"}
![](img/schooling-dag.png)

:::
::::


## Retornos da Escolaridade

::::{.columns}
:::{.column width="50%"}
$$
\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + e_i
$$

* Ele encontrou uma estimativa para $\rho$ de cerca de 0,11,

* 11% de vantagem nos ganhos para cada ano adicional de educação

* Veja o DAG. Esse é um bom modelo? Bem, por que não seria?
:::


:::{.column width="50%"}
![](img/schooling-dag.png)
:::

::::

## Viés de Habilidade

::::{.columns}
:::{.column width="50%"}
* Comparamos os ganhos de homens com certa escolaridade e experiência de trabalho

* Tudo o mais é igual, depois de controlar isso?

* Dado $X$,
     * Podemos encontrar trabalhadores mais ou menos diligentes por aí?
     * Podemos encontrar trabalhadores com capacidades diferentes?
     * As conexões familiares dos trabalhadores variam?
:::



:::{.column width="50%"}
* Sim claro. Então, *todo o resto* não é igual.

* Isso é um problema, porque para consistência dos MQO exigimos a suposição de ortogonalidade
$$E[e_i | S_i, X_i] = 0$$

* Vamos introduzir a **habilidade** $A_i$ explicitamente.
:::
::::



## Mincer com Habilidade não Observada

::::{.columns}
:::{.column width="50%"}
* Na verdade temos *dois* fatores não-observáveis: $e$ e $A$.

* Claro que não podemos distingui-los.

* Então definimos um novo fator não observável
$$u_i = e_i + A_i$$

:::


:::{.column width="50%"}

![](img/schooling-dag2.png)
:::

::::

## Mincer com Habilidade não Observada

::::{.columns}
:::{.column width="50%"}
* Em termos de uma equação:
$$\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + \underbrace{u_i}_{A_i + e_i}$$

* Às vezes, isso não importa e o viés dos MQO é pequeno.

* Às vezes importa, e a estimação é totalmente errada!
:::


:::{.column width="50%"}

![](img/schooling-dag2.png)
:::
::::


# Mecânica das Variáveis Instrumentais

## Identificação

Vamos voltar ao nosso modelo linear simples:

$$
y = \beta_0 + \beta_1 x + u
$$

onde tememos que $Cov(x,u) \neq 0$, $x$ seja *endógeno*.

## Condições para VI

1. **Relevância do Instrumento**: $Cov(z,x) \neq 0$
1. **Exogenidade do VI** (restrição de exclusão): $Cov(z,u) = 0$, a VI é exógena na equação do resultado.




## Modelo Válido (A) vs Modelo Inválido (B) para VI `z`

::::{.columns}
:::{.column width="50%"}

```{python}
# Define the graph
G1 = nx.DiGraph()

# Add nodes
G1.add_nodes_from(["z", "x", "u", "y"])

# Add edges
G1.add_edges_from([("z", "x"), ("x", "y"), ("u", "x"), ("u", "y")])

# Set node positions using planar layout
pos = {"z": (0, 0), "x": (1, 0), "u": (2, 1), "y": (3, 0)}


nx.draw(
    G1,
    pos,
    with_labels=True,
    node_color=["green", "green", "grey", "green"],
    node_size=5000,
    font_size=12,
    edge_color="black",
    linewidths=2,
    width=2,
)
ax = plt.gca()
ax.margins(0.20)
plt.title("(A)")
plt.show()
```

:::

:::{.column width="50%"}

```{python}
# Define the graph
G2 = nx.DiGraph()

# Add nodes
G2.add_nodes_from(["z", "x", "u", "y"])

# Add edges
G2.add_edges_from([("z", "x"), ("u", "z"), ("x", "y"), ("u", "x"), ("u", "y")])

# Set node positions using planar layout
pos = {"z": (0, 0), "x": (1, 0), "u": (2, 1), "y": (3, 0)}


nx.draw(
    G2,
    pos,
    with_labels=True,
    node_color=["green", "green", "grey", "green"],
    node_size=5000,
    font_size=12,
    edge_color="black",
    linewidths=2,
    width=2,
)
ax = plt.gca()
ax.margins(0.20)
plt.title("(B)")
plt.show()
```

:::
::::


## Identificação

::::{.columns}
:::{.column width="50%"}

**Condições para VI**

1. **Relevância**: $Cov(z,x) \neq 0$
2. **Exogeneidade**: $Cov(z,u) = 0$

:::

:::{.column width="50%"}

* Como isto ***identifica*** $\beta_1$?

* Como podemos expressar $\beta_1$ em termos de momentos populacionais de forma única?

:::

::::

## Identificação

$$
\begin{aligned}
Cov(z,y) &= Cov(z, \beta_0 + \beta_1 x + u) \\
         &= \beta_1 Cov(z,x) + Cov(z,u) 
\end{aligned}
$$

::::{.columns}
:::{.column width="50%"}
Sob a condição 2. acima (**restrição de exclusão**), temos que $Cov(z,u)=0$, então:

$$
Cov(z,y) = \beta_1 Cov(z,x) 
$$
:::



:::{.column width="50%"}
e sob a condição 1. (**relevância**), temos $Cov(z,x)\neq 0$, portanto:

$$
\beta_1 =  \frac{Cov(z,y)}{Cov(z,x)}.
$$

:::
::::

* $\beta_1$ é ***identificado*** via os momentos populacionais $Cov(z,y)$ e $Cov(z,x)$ 

* Podemos ***estimar*** estes momentos através dos ***análogos amostrais*** (_sample plugin estimator_)



## Estimador de Variáveis Instrumentais

Basta "plugar" os momentos **amostrais**:

$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (z_i - \bar{z})(y_i - \bar{y})}{\sum_{i=1}^n (z_i - \bar{z})(x_i - \bar{x})}$$

* A estimativa do intercepto é $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$ 



* Dado que ambas as hipóteses 1. e 2. são satisfeitas, dizemos que ***o estimador de VI é consistente para $\beta_1$*** e escrevemos:
$$
\text{plim}(\hat{\beta}_1) = \beta_1
$$

- em palavras: o *limite em probabilidade* de $\hat{\beta}_1$ é o verdadeiro $\beta_1$. O estimador $\hat{\beta}_1$ converge em probabilidade para o parâmetro populacional

- Se isso for verdade, dizemos que este estimador é **consistente**.


## Inferência com Variáveis Instrumentais

Assumindo $E(u^2|x,z) = \sigma^2$ a variância do estimador de VI é:

$$Var(\hat{\beta}_{1,IV}) = \frac{\sigma^2}{n \sigma_x^2 \rho_{x,z}^2}$$

* $\sigma_x^2$ é a variância populacional de $x$,

* $\sigma^2$ é a variância de $u$, e

* $\rho_{x,z}$ é a correlação populacional entre $x$ e $z$.



- Você pode ver 2 coisas importantes aqui:

  1. Sem o termo $\rho_{x,z}^2$, isso é **a variância do MQO**.
  2. A medida que o tamanho da amostra $n$ aumenta, a **variância diminui** (assim como no MQO).


## Variância de VI é sempre maior que MQO

Compare as variâncias de MQO e VI:


::::{.columns}

:::{.column width="50%"}
- $Var(\hat{\beta}_{1}) = \frac{\sigma^2}{n \sigma_x^2}$
:::

:::{.column width="50%"}
- $Var(\hat{\beta}_{1,IV}) = \frac{\sigma^2}{n \sigma_x^2 \rho_{x,z}^2}$
:::

::::

1. Dado $\rho_{x,z}^2 < 1$ na maioria das situações da vida real, temos que $Var(\hat{\beta}_{1,IV}) > Var(\hat{\beta}_ {1})$ quase certamente.


1. Quanto maior a correlação entre $z$ e $x$, mais próximo o $\rho_{x,z}^2$ está de 1 e voltamos a variância do MQO.



## Variância de VI é sempre maior que MQO

<img align="center" src="https://media.giphy.com/media/Xg4Lc2tzOXXdNCU4Qc/giphy.gif" width="90"> 

Se tiverermos um regressor exógeno válido $x$, **não** devemos usar VI $z$ para obter $\hat{\beta}$, pois sua variância será desnecessariamente grande.


## Estimador de variância com VI

Novamente utilizamos os análogos amostrais

* $n\sigma_x^2$ é a $SQT_x=\sum_i (x_i - \bar{x})^2$
* $\rho_{x,z}^2$ é estimado via $R_{x,z}^2$. R2 de uma regressão simples de $x$ em $z$
* a variância de $u$ é obtida através do estimador:
$$\hat{\sigma}^2=\frac{1}{n-2}\sum_{i=1}^{n}\hat{u}_i^2$$
onde $\hat{u}_i=y_i-\hat\beta_0-\hat\beta_{1, IV} x_i$

* Portanto, $\widehat{Var}(\hat{\beta}_{1,IV}) = \frac{\hat\sigma^2}{\sum_i (x_i - \bar{x})^2 R_{x,z}^2}$

## Como Saber se a VI é Válida?

Sempre avaliamos uma candidata a VI através das 2 condições:

- **Condições para VI**

    1. **Relevância**: $Cov(z,x) \neq 0$
    2. **Exclusão**: $Cov(z,u) = 0$


* Somente a condição **1.** pode ser testada empiricamente!

* :warning: Restrição de exclusão é hipótese não testável
    + Pesquisador deve se valer de teoria econômica e arguição lógica


## Mínimos Quadrados em 2 Estágios: MQ2E

- **Equação estrutural**: $y_i=\beta_0+\beta_1 s_i + \beta_2 x_i + u_i$


1. Estimamos um **modelo de primeiro estágio** que usa apenas variáveis exógenas (como $z$) para explicar nosso regressor endógeno $s$.

2. Em seguida, usamos a **previsão** do 1º estágio, $\hat{s}$, no que é chamado de modelo de **segundo estágio**. Esse procedimento deve eliminar qualquer endogeneidade entre $\hat{s}$ e $y$.

:::{.fragment}
$$
\begin{aligned}
\text{1. Estágio: }s_i &= \alpha_0 + \alpha_1 z_i + \alpha_2 x_i + \eta_i \\
\text{2. Estágio: }y_i &= \beta_0 + \beta_1 \hat{s}_i + \beta_2 x_i + \varepsilon_i
\end{aligned}
$$

:::

- **Condições:**

  1. Relevância do IV: $\alpha_1 \neq 0$
  1. Exogeneidade (restrição de exclusão): $E[u | z] = 0$


## Mínimos Quadrados em 2 Estágios: MQ2E

- O primeiro estágio isola a endogeneidade no termo de erro $\eta_i$
$$s_i=\underbrace{\alpha_0 + \alpha_1 z_i + \alpha_2 x_i}_{\hat{s}_i\text{: parte exógena}} + \eta_i$$

- E utiliza somente a parte exógena no segundo estágio!
$$y_i = \beta_0 + \beta_1 \hat{s}_i + \beta_2 x_i + \varepsilon_i$$
Assim o segundo estágio faz uso somente de ***variações exógenas*** de $s_i$ e, portanto, $\hat{\beta}_1$ será não viesado.


- :warning: o primeiro estágio **DEVE** ser linear. Caso contrário, regressão proibida de Hausman! (MHE ch. 4, p. 142)

- Não realizamos manualmente porque os erros padrão no 2º estágio estarão errados


:::{.fragment}
<center>**Vejamos em um exemplo**</center>
:::

## Vamos implementar Angrist e Krueger (1991)! 

### Data de nascimento é tão boa quanto aleatória


::::{.columns}
:::{.column width="50%"}
* Angrist e Krueger (AK91) é um estudo influente que aborda o viés de habilidade

     1. construir uma VI que codifique a *data de nascimento do aluno*
     1. A criança nascida logo após a data limite começará a escola mais tarde!
    
* Crianças que completam 6 anos até 31 de dezembro devem se matricular na 1ª série em setembro do mesmo ano
:::

:::{.column width="50%"}
* Nascidos em dezembro de 2016, estarão com 5a9m quando começarem a escola

* Nascidos em 1º de janeiro de 2017 estarão com 6a9m quando *estes* entrarem na escola em setembro de 2023

* Podem legalmente abandonar a escola quando fazem 16 anos! Alguns terão mais escolaridade que outros

* VI Dummy para *trimestre de nascimento*: afeta a escolaridade, mas não está relacionado a $A$!
:::
::::


## Setup com Variável Instrumental

::::{.columns}
:::{.column width="50%"}
* *trimestre de nascimento* dummy $z$: afeta a escolaridade, mas não está relacionada a $A$!

* Em particular: se nasceu no 4º trimestre ou não.
:::

:::{.column width="50%"}

:::{.fragment}
![](img/schooling-dag3.png){width=100%}
:::

:::
::::


## Dados sobre aniversário e salários

Vamos carregar os dados e olhar seu sumário

```{python}
#| echo: true

# Dados baixados de https://www.masteringmetrics.com/resources/
ak91_file = "../../../data/ak91.dta"
ak91 = pd.read_stata(ak91_file)
# Estatisticas descritivas
ak91.describe()
```

## Transformações dos Dados

* Queremos criar  uma _dummy_ `q4` que é `TRUE` se você nasceu no 4º trimestre.

* criar versões `factor` de trimestre e ano de nascimento.

```{python}
#| echo: true
ak91['qob_fct'] = ak91['qob'].astype('category')
ak91['q4'] = (ak91['qob'] == 4.0).astype(int)
ak91['yob_fct'] = ak91['yob'].astype('category')

ak91_age = ak91.groupby(['qob', 'yob']).agg(lnw=('lnw', 'mean'), s=('s', 'mean')).reset_index()
ak91_age['q4'] = (ak91_age['qob'] == 4)
```


## Primeiro Estágio!

Vamos reproduzir agora a primeira figura de AK91 sobre educação em função do trimestre de nascimento!


::::{.columns}
:::{.column width="30%"}

1. Os números rotulados significam trimestre de nascimento.

1. Nascidos no 4º trimestre **obtiveram** mais educação na maioria dos anos!

1. **Relevância da VI**.
:::

:::{.column width="70%"}

```{python}
#| echo: true
fig, ax = plt.subplots(figsize=(14,8))

ak91_age['yob_qob'] = ak91_age['yob'] + (ak91_age['qob'] - 1) / 4
sort_df = ak91_age.sort_values('yob_qob')

ax.plot(sort_df['yob_qob'], sort_df['s'])

for i, txt in enumerate(sort_df['qob'].astype('int')):
    ax.annotate(txt, (sort_df['yob_qob'].iloc[i], sort_df['s'].iloc[i]), 
    fontsize=20,
    bbox=dict(boxstyle='round,pad=0.2', 
    fc=sort_df['q4'].map({False: 'yellow', True: 'purple'}).iloc[i], 
    alpha=0.8))

ax.grid(True)
ax.set_xlabel('Ano de Nascimento')
ax.set_ylabel('Anos de Escolaridade')
plt.show()
```
:::

::::


## Impacto da VI no resultado

E quanto aos salários para esses grupos?

::::{.columns}
:::{.column width="30%"}

1. Nascidos no 4º trimestre estão entre os mais bem pagos por ano de nascimento.

1. Em geral, os salários semanais parecem diminuir um pouco ao longo do tempo.

1. Visualização da **forma reduzida**
:::

:::{.column width="70%"}

```{python}
#| echo: true
fig, ax = plt.subplots(figsize=(14,8))

ax.plot(sort_df['yob_qob'], sort_df['lnw'])

for i, txt in enumerate(sort_df['qob'].astype('int')):
    ax.annotate(txt, (sort_df['yob_qob'].iloc[i], sort_df['lnw'].iloc[i]), 
    fontsize=20,
    bbox=dict(boxstyle='round,pad=0.2', 
    fc=sort_df['q4'].map({False: 'yellow', True: 'purple'}).iloc[i], 
    alpha=0.8))

ax.grid(True)
ax.set_xlabel('Ano de Nascimento')
ax.set_ylabel('Log Salário Semanal')
plt.show()
```

:::
::::


<!-- ## Executando estimativa VI no `R`

<br>
<br>

::::{.columns}
:::{.column width="50%"}
* Várias opções (como sempre com `R`! 😉)

* Usaremos a função [`iv_robust`](https://declaredesign.org/r/estimatr/reference/iv_robust.html) do pacote `estimatr`.

* *Robusto*? Calcula erros padrão que estão corrigindo a heterocedasticidade. [Detalhes aqui.](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html)
:::

:::{.column width="50%"}

```{r mq2e, cache=TRUE}
library(estimatr)
# create a list of models
mod <- list()

# standard (biased!) OLS
mod$ols <- lm(lnw ~ s, data = ak91)

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
mod$stage_1 <- lm(s ~ q4, data = ak91)
ak91$shat <- predict(mod$stage_1)  
mod$stage_2 <- lm(lnw ~ shat, data = ak91)

# run 2SLS
# doing IV all in one go
# notice the formula!
# formula = y ~ x | z
mod$MQ2E  <- iv_robust(lnw ~ s | q4,
                       data = ak91,
                       diagnostics = TRUE)
```

:::
:::: -->

## Executando estimativa VI no `Python`

::::{.columns}
:::{.column width="50%"}
* A melhor biblioteca para implementar estimativas de VI no `Python` é o [`linearmodels`](https://bashtage.github.io/linearmodels/).

* Usaremos a função `IV2SLS` que inclui a sintaxe de formula, também usada no [`statsmodels`](https://www.statsmodels.org/stable/index.html)

* *Robusto*? Calcula **por padrão** erros corrigidos para heterocedasticidade. Argumento `cov_type`. @sec-robust
:::

:::{.column width="50%"}

```{python}
#| echo: true

import linearmodels.iv as iv

# Standard (biased!) OLS
ols = iv.IV2SLS.from_formula('lnw ~ 1+s', data=ak91).fit()

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
stage_1 = iv.IV2SLS.from_formula('s ~ 1+q4', data = ak91).fit()
ak91['shat'] = stage_1.predict()  
stage_2 = iv.IV2SLS.from_formula('lnw ~ 1+shat', data = ak91).fit()

# Run 2SLS. Doing IV all in one go
# Notice the formula y ~ [x ~ z]
MQ2E = iv.IV2SLS.from_formula('lnw ~ 1 + [s ~ q4]', data = ak91).fit()
```

:::
::::

<!-- ## Executando estimativa VI no `R`

<br>
<br>

::::{.columns}
:::{.column width="50%"}
* Várias opções (como sempre com `R`! 😉)

* Usará a função [`iv_robust`](https://declaredesign.org/r/estimatr/reference/iv_robust.html) do pacote `estimatr`.

* *Robusto*? Calcula erros padrão que estão corrigindo a heterocedasticidade. [Detalhes aqui.](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html)

* Observe o `predict` para obter $\hat{s}$.
:::


:::{.column width="50%"}

```{r, eval = FALSE}
library(estimatr)
# create a list of models
mod <- list()

# standard (biased!) OLS
mod$ols <- lm(lnw ~ s, data = ak91)

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
mod$stage_1 <- lm(s ~ q4, data = ak91)
ak91$shat <- predict(mod$stage_1) #<<
modmod$stage_2 <- lm(lnw ~ shat, data = ak91)

# run 2SLS
# doing IV all in one go
# notice the formula!
# formula = y ~ x | z
mod$MQ2E  <- iv_robust(lnw ~ s | q4,
                       data = ak91,
                       diagnostics = TRUE)
```

:::
::::
 -->

## Resultados

::::{.columns}
:::{.column width="70%"}

<!-- ```{r ms1, echo = FALSE}
glance_custom.iv_robust <- function(x){
  f = x$diagnostic_first_stage_fstatistic
  if (is.null(f)) {
    return()
  } else {
    out <- tibble::tibble(`1. Stage F:` = f["value"])
    return(out)
  }
}
library(huxtable)
tab = msummary(models = mod,
               stars = TRUE,
               statistic = 'std.error',
               gof_omit = 'DF|Deviance|AIC|BIC|R2 Adj.|p.value|F$|se_type|statistic|Log.Lik.|Num.Obs.|N',
               output = "huxtable"
)
tab %>%
  set_bottom_border(row = 9, col = everywhere) %>%
  set_tb_padding(3.5)
``` -->

```{python}
from io import StringIO
import warnings

def compare_df(x, fit_stats=['Estimator', 'R-squared', 'No. Observations'], params_slice=slice(11, None)):
    with warnings.catch_warnings():
        warnings.simplefilter(action='ignore', category=FutureWarning)
        y = pd.read_csv(StringIO(iv.results.compare(x, stars=True, precision='std_errors').summary.as_csv()), skiprows=1, skipfooter=1, engine='python')
    z = pd.DataFrame(
        data=y.iloc[:, 1:].values,
        index=y.iloc[:, 0].str.strip(),
        columns=pd.MultiIndex.from_arrays(
            arrays=[y.columns[1:], y.iloc[0][1:]],
            names=['Model', 'Dep. Var.']
        )
    )
    return pd.concat([z.iloc[params_slice], z.loc[fit_stats]])
```

```{python}
df = compare_df(
  {'OLS': ols, 'Stage 1': stage_1, 'Stage 2': stage_2, 'MQ2E': MQ2E})

# style df to print in small font
df.style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```

:::

:::{.column width="30%"}

1. MQO viesado para baixo (erro de medição)

1. Primeiro Estágio: VI `q4` é estatisticamente significativo

1. O segundo estágio tem a mesma estimativa pontual que `MQ2E`, mas um erro padrão diferente (segundo estágio está errado)
:::
::::


## Lembra da estatística F?

* Encontramos isso antes: é útil testar modelos restritos versus irrestritos entre si.


* Aqui, estamos interessados em saber se nossos instrumentos são *conjuntamente* significativos. Claro, com apenas uma VI, isso não é mais informativo do que o t-stat dessa VI.


* Este F-Stat compara o poder preditivo do primeiro estágio com e sem as VIs. Se eles tiverem poder preditivo muito semelhante, o F-stat será baixo e não poderemos rejeitar H0 de que nossas VIs são **conjuntamente insignificantes** no modelo do primeiro estágio. 😞


## VI com um instrumento fraco

* VI é consistente sob determinadas premissas.

* No entanto, *mesmo* que tenhamos apenas $Cor(z,u)$ muito pequenos, podemos errar

* Pequena correlação entre $x$ e $z$ pode produzir estimativas **inconsistentes**.
$$\text{plim}(\hat{\beta}_{1,IV}) = \beta_1 + \frac{Cor(z,u)}{Cor(z,x)} \cdot \frac{\sigma_u}{\sigma_x}$$


* Mesmo que $Cor(z,u)$ seja muito pequena

* Um **instrumento fraco** é aquele com pequeno valor absoluto para $Cor(z,x)$

* Mesmo com um tamanho de amostra grande, nosso estimador *não* convergirá para o verdadeiro parâmetro populacional $\beta_1$.




## VI com um instrumento fraco

Para ilustrar esse ponto, vamos supor que queremos analisar o impacto do número de maços de cigarros fumados por dia por mulheres grávidas (*packs*) no peso ao nascer de seus filhos (*bwght*):

$$\log(bwght) = \beta_0 + \beta_1 packs + u$$

Estamos preocupados que o comportamento de fumar esteja correlacionado com uma série de outras variáveis relacionadas à saúde que estão em $u$ e que podem afetar o peso ao nascer da criança. 

Então, procuramos uma **VI**. Suponha que usemos o **preço dos cigarros** (*cigprice*), supondo que o preço dos cigarros não esteja correlacionado com fatores em $u$. Vamos executar o primeiro estágio de *cigprice* em *packs* e então vamos mostrar as estimativas de MQ2E:



## VI com um instrumento fraco

<!-- 
```{r bw}
data(bwght, package = "wooldridge")
mods <- list()
mods$Estagio_1 <- lm(packs ~ cigprice, data = bwght)
mods$VI <- estimatr::iv_robust(log(bwght) ~  packs | cigprice, data = bwght, 
                               diagnostics = TRUE)
```

```{r,echo = FALSE}
tbl <- modelsummary(mods, gof_omit = 'DF|Deviance|AIC|BIC|R2 Adj.|p.value|F$|se_type|statistic|Log.Lik.|Num.Obs.|N', output = "huxtable") %>%
    set_bottom_border(row = 7, col = everywhere) %>%
    set_bold(1, everywhere) %>%
    set_tb_padding(5)
font_size(tbl) <- 15
tbl
``` -->

```{python}
#| echo: true
import wooldridge as woo
bwght = woo.dataWoo('bwght')
estagio_1 = iv.IV2SLS.from_formula('packs ~ 1 + cigprice', data = bwght).fit()
vi = iv.IV2SLS.from_formula('np.log(bwght) ~ 1 + [packs ~ cigprice]', data = bwght).fit()
```

```{python}
compare_df({'Estágio 1': estagio_1, 'VI': vi}, fit_stats=['Estimator', 'R-squared', 'No. Observations', 'F-statistic']).style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```



## VI com um instrumento fraco

::::{.columns}
:::{.column width="50%"}

* A primeira coluna mostra: primeiro estágio muito fraco. *cigprice* parece ter zero impacto na quantidade de maços consumidos!

* $R^2$ é zero.

* Por quê usamos esta VI?
:::



:::{.column width="50%"}

* na segunda coluna: impacto muito grande e positivo(!) dos maços fumados no peso ao nascer. 🤔

* Enorme erro padrão.

* Um $R^2$ de -23?!

* F-stat do primeiro estágio: 0,121. Corresponde a um valor p de 0.728 : nós **não podemos** rejeitar a H0 de um primeiro estágio insignificante.

* Então: abordagem **inválida**. ❌
:::
::::



## Variáveis de Controle Adicionais

* Vimos uma tendência de tempo clara na educação mais cedo.

* Há também flutuações do ciclo de negócios nos ganhos

* Devemos de alguma forma controlar por diferentes períodos de tempo.

* Além disso, podemos usar mais de uma VI! Aqui está como:



## Variáveis de Controle Adicionais

<!-- ```{r mq2e2, cache=TRUE}
# we keep adding to our `mod` list:
mod$ols_yr  <- update(mod$ols, . ~ . + yob_fct)  #  previous OLS model

# add exogenous vars on both sides of the `|` !
mod$MQ2E_yr <- iv_robust(lnw ~ s  + yob_fct | q4 + yob_fct, 
                         data = ak91, diagnostics = TRUE ) 

# use all quarters as IVs
mod$MQ2E_all <- iv_robust(lnw ~ s  + yob_fct | qob_fct + yob_fct, 
                          data = ak91, diagnostics = TRUE  )
``` -->

```{python}
#| echo: true
ols_yr = iv.IV2SLS.from_formula('lnw ~ 1+s+yob_fct', data=ak91).fit()
mq2e_yr = iv.IV2SLS.from_formula('lnw ~ 1+yob_fct+[s ~ q4]', data=ak91).fit()
# Use all quarters as IVs
# mq2e_all = iv.IV2SLS.from_formula('lnw ~ 1+yob_fct+[s ~ qob_fct]', data=ak91).fit()
```

## Variáveis de Controle Adicionais

<!-- ```{r, echo = FALSE}
# here is how to make the table:
rows <- data.frame(term = c("Instruments","Year of birth"),
                   ols  = c("none","no"),
                   SLS  = c("Q4","no"),
                   ols_yr  = c("none","yes"),
                   SLS_yr  = c("Q4","yes"),
                   SLS_all  = c("All Quarters","yes")
                   )
names(rows)[c(3,5,6)] <- c("2SLS","2SLS_yr","2SLS_all")
tab = msummary(models = mod[c("ols","MQ2E","ols_yr","MQ2E_yr","MQ2E_all")], 
               statistic = 'std.error',
               gof_map = gm,
               add_rows = rows,
               coef_omit = 'yob_fct',
               output = 'huxtable')

htab = tab %>%
  set_bottom_border(row = 6, col = everywhere) %>%
  set_bold(1, everywhere) %>%
  set_tb_padding(4)

htab
``` -->

::::{.columns}
:::{.column width="70%"}


```{python}
compare_df(
  {'OLS': ols, 'MQ2E': MQ2E, 'OLS + Year': ols_yr, 'MQ2E + Year': mq2e_yr}, 
  fit_stats=['Estimator', 'Adj. R-squared', 'No. Observations'],
  params_slice=slice(11,13)).style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```
:::

:::{.column width="30%"}
**Adicionando controle de ano**...

* deixa o MQO praticamente inalterado
* ligeiro aumento na estimativa de MQ2E

<!-- **Usando todos os trimestres como VI**...

* Aumenta muito a precisão da estimativa MQ2E!
* A estimativa pontual é de 10,5% agora! -->

:::
::::



## Fazendo um balanço - O Trimestre de Nascimento (QOB)

::::{.columns}
:::{.column width="50%"}
* Isso produzirá estimativas consistentes se
     1. A VI prediz bem o regressor endógeno.
     2. A VI é tão boa quanto aleatória/independente das VOs.
     3. Só pode impactar o resultado através da escolaridade.
    
* Como o QOB se comporta com relação a estes itens?
:::



:::{.column width="50%"}

1. O gráfico do 1º estágio e o F-stat alto oferecem evidências de **relevância**. ✅

2. O QOB é **independente** de, digamos, *características maternas*? Aniversários não são realmente aleatórios - há épocas de nascimento para certas origens socioeconômicas. maior escolaridade materna dão à luz no segundo trimestre. (não no 4º! ✅)

3. Exclusão: E se as crianças mais novas (nascidas no 4º tri!) forem desfavorecidas desde o início, que tem impactos negativos a longo prazo? Então $E[u|z] \neq 0$! Bem, os mais novos se saem melhor (mais escolaridade e salário mais alto)! ✅
:::
::::

# Teorema LATE

## Heterogeneidade e Efeito Médio Local

- Suponha que os retornos de escolaridade são heterogêneos. VI será uma média destes retornos. Mas **que média** :question:

- **Efeito Médio do Tratamento Local** (local average treatment effect - LATE) é a média do efeito do tratamento para os indivíduos que são _"compliers"_ (ou seja, que mudam seu comportamento quando induzidos pelo instrumento).

- Focaremos no caso mais simples: um tratamento binário e um instrumento binário. (estimador de Wald para MQ2E)

## Notação de Resultados Potenciais

- Escolaridade para indivíduo $i$ (tratamento) será $D_i = \{0,1\}$. Exemplo, $D_i=1$ se o indivíduo completou o ensino médio.

- Renda é denotada por $Y_i$.

- Renda **potencial** de $i$ para um nível de escolaridade $d$ é $Y_i(d)$.

- Tudo isso já sabíamos. Mas agora vamos adicionar um **instrumento** $Z_i = \{0,1\}$ que afeta a escolaridade $D_i$.

## Notação de Resultados Potenciais

- Escolarida agora para a ser ***"tratada"*** pelo instrumento $Z_i$. Recebe também uma notação potencial.
  + $D_i(Z_i)$

- Renda pode ser indexada como resultado de escolaridade e instrumento.
  + $Y_i(D_i, Z_i)$. Existem 4 possíveis resultados potenciais.

:::{.fragment}
\begin{aligned}
\begin{cases}
Y_i(0,0) & \text{se } D_i=0, Z_i=0 \\
Y_i(1,0) & \text{se } D_i=1, Z_i=0 \\
Y_i(0,1) & \text{se } D_i=0, Z_i=1 \\
Y_i(1,1) & \text{se } D_i=1, Z_i=1 \\
\end{cases}
\end{aligned}
:::

## Hipóteses do Teorema LATE

Serão necessárias **quatro** hipóteses para que o LATE seja identificado:

1. **Independência**: $\{Y_i(0, 0), Y_i(1, 0), Y_i(0, 1), Y_i(1, 1), D_i(0), D_i(1)\} \perp Z_i$

2. **Exclusão**: $Y_i(d, 0) = Y_i(d, 1)$ para $d\in\{0,1\}$

3. **Relevância**: $E[D_i(1)-D_i(0)]\neq 0$

4. **Monotonicidade**: $D_i(1)\geq D_i(0)$, para todo $i$

- Destas, somente a hipótese **4** é nova.
  + Na prática ela exclui a presença de ***desafiantes*** (_defiers_) na população.

## Status de _Compliance_ do Instrumento

- Dado que o instrumento assume um valor, o efetivo tratamento pode ou não ser influenciado por este instrumento. 

- No caso 2x2 que estamos tratando, existem quatro possíveis status de $D_i(Z_i)$:

:::{.fragment}
\begin{cases}
D_i(0)=D_i(1)=0, \text{ never taker},\\
D_i(0)=D_i(1)=1, \text{ always taker},\\
D_i(0)=0, D_i(1)=1, \text{ complier},\\
D_i(0)=1, D_i(1)=0, \text{ defier},
\end{cases}
:::

- Veja que a hipótese de **monotonicidade implica na ausência de desafiantes** (_defiers_)
  + Para um desafiante, $D_i(1) < D_i(0)$

## Teorema LATE

:::{#thm-late}
## LATE

Sob as hipóteses 1-4, o estimador MQ2E é dado por:

$$
\frac{E[Y_i|Z_i=1]-E[Y_i|Z_i=0]}{E[D_i|Z_i=1]-E[D_i|Z_i=0]}=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]
$$
:::

- O LATE é a média do efeito do tratamento para os indivíduos que são _"compliers"_ (ou seja, que mudam seu comportamento quando induzidos pelo instrumento).

:::{.fragment}
:::{.center}
:warning: **Método de VI sob as hipóteses 1-4 é um estimador de LATE**
:::
:::

## Teorema LATE - Prova

:::{.proof}
## Prova
Podemos escrever o numerador como:

$$
\begin{aligned}
E[Y_i|Z_i=1]-E[Y_i|Z_i=0]&=E[Y_i(D_i(1),1)-Y_i(D_i(0),0)]\\
&=\sum_{g\in\{co, nt, at, df\}}E[Y_i(D_i(1),1)-Y_i(D_i(0),0)|G_i=g]\cdot P[G_i=g]\\
\end{aligned}
$$

onde $g$ é o status de compliance (complier, never taker, always taker, defier).

- O efeito médio para os grupos _"never taker"_ e _"always taker"_ é zero pela restrição de exclusão.

- A probabilidade de haver um _"defier"_ é zero pela hipótese de monotonicidade.

:::{.fragment}
Portanto:

$$E[Y_i|Z_i=1]-E[Y_i|Z_i=0]=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]\cdot P[D_i(1)>D_i(0)]$$
:::

:::

## Teorema LATE - Prova

:::{.proof}
## Prova
Agora, o denominador:

$$
\begin{aligned}
E[D_i|Z_i=1]-E[D_i|Z_i=0]&=E[D_i(1)-D_i(0)]\\
&=P[D_i(1)>D_i(0)].\\
\end{aligned}
$$

:::{.fragment}
Portanto:

$$
\begin{aligned}
\frac{E[Y_i|Z_i=1]-E[Y_i|Z_i=0]}{E[D_i|Z_i=1]-E[D_i|Z_i=0]}&=\frac{E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]\cdot P[D_i(1)>D_i(0)]}{P[D_i(1)>D_i(0)]}\\
\text{LATE}&=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]
\end{aligned}
$$
:::

:::

# Tópicos Especiais VI

## Experimentos Aleatorizados

* Experimento aleatorizado (RCT ou A/B testing)


* Atribui indíviduos para grupos Controle ou Tratado, mas não obriga


* Existe _noncompliance_. Tratamento efetivo $T_i \neq Z_i$ designação


* **Atribuição ao tratamento** $Z_i$ serve como **instrumento** para o efetivo status $T_i$



# Tópicos Especiais VI

## Experimentos Aleatorizados

* Duas medidas de tratamento
    + Intention-to-treat (**ITT**): forma reduzida $Y_i=\pi Z_i+v_i$
    + Local Average Treatment Effect (**LATE**): variável instrumental (MQ2E)


* Para validade do experimento, checa-se o balanço de covariadas entre grupo controle e tratamento
* Bom balanço $\implies$ aleatorização bem feita. (Imbens e Rubin, 2015)



# Tópicos Especiais VI

## Instrumentos de Bartik

> A ideia por trás de um instrumento de Bartik é medir variações locais a partir de um choque nacional (regional)



* Também conhecidos como ***Shift-Share design***



* Comuns na literatura de comércio internacional (Autor, Dorn, e Hanson, 2013), imigração (Card, 2009) e trabalho (Bound e Holzer, 2000)



* ***Bartik Instruments: What, When, Why, and How***. Goldsmith-Pinkham, et al. (2020)



# Tópicos Especiais VI

## Instrumentos de Bartik

* Um choque nacional (_**shifter**_), em diferentes indústrias, é "espalhado" localmente de forma diferente entre as localidades através de uma matriz de exposições (_**shares**_)


* Crescimento do salário em razão do crescimento no emprego, em uma localidade $l$
$$y_l=\rho+\beta_1x_l+\epsilon_l$$

* Crescimento do emprego é *produto interno* da fração de cada indústria $k$ no emprego com o crescimento desta indústria. $x_l=\sum_kz_{lk}g_{lk}$


* Crescimento da indústria local é decomposto: $g_{lk}=g_k+\tilde{g}_{lk}$



* O ***Instrumento de Bartik*** é: $$Z_l=\sum_k z_{lk}g_k$$



## :books: Leitura Recomendada

* WOOLDRIDGE, Jeffrey M. Introdução à econometria: uma abordagem moderna. São Paulo: Cengage Learning, 2016. Tradução da 4ª edição norte-americana por José Antonio Ferreira. Capítulo 15.

* GUJARATI, Damodar N.; PORTER, Dawn C. Econometria básica. Porto Alegre: Amgh Editora, 2011. - 5. ed. Capítulo 17

* ANGRIST, Joshua D.; PISCHKE, Jörn-Steffen. Mostly harmless econometrics: An empiricist's companion. Princeton university press, 2009.

* IMBENS, Guido W.; RUBIN, Donald B. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.

* GOLDSMITH-PINKHAM, Paul; SORKIN, Isaac; SWIFT, Henry. Bartik instruments: What, when, why, and how. American Economic Review, v. 110, n. 8, p. 2586-2624, 2020. DOI: [10.1257/aer.20181047](https://doi.org/10.1257/aer.20181047)

* GREWAL, Rajdeep; ORHUN, Yesim. Unpacking the Instrumental Variables Approach. Impact at JMR, Journal of Marketing Research (August 23). Url: [https://www.ama.org/marketing-news/unpacking-the-instrumental-variables-approach/](https://www.ama.org/marketing-news/unpacking-the-instrumental-variables-approach/)

## ATÉ A PRÓXIMA AULA!


:::footer
[1]: Este slides foram baseados nas aulas de econometria da [SciencesPo Department of Economics](https://github.com/ScPoEcon/ScPoEconometrics-Slides)
:::


# Apêndice

## Erros Padrão Robustos{#sec-robust}

- Resíduos representa a diferença entre a variável dependente o a média estimada.[^1]
$$
\begin{aligned}
y = X\hat\beta + \hat{u}\\
\hat{u} = y − X\hat{\beta}
\end{aligned}
$$

- Variância de \hat{\beta} depende dos erros.
$$
\begin{aligned}
Var(\hat{\beta}\mid X) &= E[(X'X)^{-1}X'uu'X(X'X)^{-1}\mid X]\\
&= (X'X)^{-1}X'E[uu'\mid X]X(X'X)^{-1}\\
&= (X'X)^{-1}X'\Sigma X(X'X)^{-1}\\
\end{aligned}
$$

- $\Sigma=E[uu'\mid X]$. Uma matriz $n\times n$

[^1]: Notação matricial, y é um vetor de $n\times 1$, X é uma matriz $n\times k$, \beta é um vetor $k\times 1$ e u é um vetor $n\times 1$.

## Erros Padrão Robustos

- Se os erros são **homocedásticos**, então $\Sigma=\sigma^2I_n$ e o estimador de variância do MQO: $\hat{V}^{mqo}(\hat{\beta}\mid X)=\hat\sigma^2(X'X)^{-1}$. 

- Se os erros são **heterocedásticos**, o ***estimador de variância*** do MQO é inconsistente!
  + Veja que o estimador de MQO de $\beta$ ainda é consistente

- O **estimador de variância robusto** a heterocedasticidade proposto por White é:
$$
\begin{aligned}
\hat{V}^{rob}(\hat{\beta}\mid X) &= (X'X)^{-1}X'\hat{\Sigma}X(X'X)^{-1}\\
\hat{\Sigma} &= \begin{bmatrix}
\hat{u}_1^2 & 0 & \cdots & 0\\
0 & \hat{u}_2^2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & \hat{u}_n^2\\
\end{bmatrix}
\end{aligned}
$$
