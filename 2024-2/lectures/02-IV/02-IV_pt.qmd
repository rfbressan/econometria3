---
title: "Econometria III"
subtitle: "Vari√°veis Instrumentais"
title-slide-attributes:
  data-background-image: "img/UdescEsag.jpeg"
  data-background-size: 50%
  data-background-position: top left
  # data-background-opacity: "0.7"
center-title-slide: true
author: "Rafael Bressan"
logo: "img/UdescEsag.jpeg"
format: 
  revealjs:
    theme: [default, ../udesc.scss] 
    code-fold: true
    # chalkboard: true
    incremental: true
    width: 1600
    height: 900
    embed-resources: true
from: markdown+emoji # list of emojis: https://gist.github.com/rxaviers/7360908
fontsize: "2.2em"
# editor: source
jupyter: python3
---

```{python}
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
```

## Preparando a cena


* Nos cap√≠tulos [7](https://scpoecon.github.io/ScPoEconometrics/causality.html), [8](https://scpoecon.github.io/ScPoEconometrics/STAR.html) e [9](https ://scpoecon.github.io/ScPoEconometrics/RDD.html) do livro `Introduction to Econometrics with R` √© falado sobre os m√©ritos dos _m√©todos experimentais_.

* Experimentos aleatorizados (RCTs) ou configura√ß√µes _Quasi-experimentais_ (t√£o bons quanto aleat√≥rios) nos permitem estimar efeitos **causais**.

* Se as pessoas tiverem algum tipo de op√ß√£o sobre a ingest√£o do tratamento, haver√° *sele√ß√£o*.

* RCTs podem quebrar a auto-sele√ß√£o de pessoas em tratamento, designando-as aleatoriamente.

* Ent√£o, com dados experimentais, temos uma boa solu√ß√£o.

* E os dados n√£o experimentais?


## Dados n√£o experimentais

::::{.columns}
:::{.column width="50%"}

* Falamos sobre **vi√©s de vari√°vel omitida**.

* E se houver correla√ß√£o entre uma vari√°vel no termo de erro $u$, $x_2$ digamos, e nossa vari√°vel explicativa $x_1$?

* Obteremos estimativas tendenciosas porque n√£o podemos separar o que √© o qu√™: efeito de $x_1$, ou de $x_2$?

* Lembre-se de que isso pode ser t√£o grave que nem conseguimos o sinal correto de um efeito.
:::

:::{.column width="50%"}

![](img/IV_ovb_dag.png)

:::
::::


<center>
- **VI** fornece uma solu√ß√£o para VVO.
</center>

## Endogeneidade

- Sempre que uma vari√°vel explicativa em uma regress√£o m√∫ltipla for **correlacionada com o termo de erro**, dizemos que esta vari√°vel √© **end√≥gena**

:::{.fragment}
$$
y=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k + \varepsilon
$$
:::

- $E[\varepsilon \mid x_1, \ldots x_k]\neq 0$

- Endogeneidade pode ocorrer por diversos motivos:
    + Forma funcional mal especificada
    + Omiss√£o de vari√°vel relevante
    + Erro de medida nos regressores
    + Determina√ß√£o simult√¢nea entre vari√°vel dependente e independentes

## RCT Resolve Endogeneidade

- Considere uma especifca√ß√£o linear para estimar o efeito causal de $x$ em $y$
$$y=\beta_0 +\beta_1 x + \varepsilon$$

- Com **dados observacionais** √© f√°cil imaginar que omitimos diversas vari√°veis que ajudam a explicar $y$ e s√£o correlacionadas com $x$. $E[\varepsilon\mid x]\neq 0$.
    + :warning: **Endogeneidade**

- Quando realizamos um experimento aleatorizado, $x$ passa a ser uma vari√°vel atribu√≠da de forma **independente** de qualquer outro poss√≠vel regressor omitido. $E[\varepsilon\mid x]=0$.
    + $x$ passou a ser um regressor **ex√≥geno**
    + $\beta_1$ pode ser interpretado como efeito causal de $x$ em $y$

## Modelo de Transmiss√£o do C√≥lera de Snow


* Suponha que $c_i$ assuma o valor 1 se o indiv√≠duo $i$ morrer de c√≥lera, 0 caso contr√°rio.

* Seja $w_i = 1$ significando que o abastecimento de √°gua de $i$ √© impuro e $w_i = 0$ vice-versa. A pureza da √°gua √© avaliada com uma tecnologia que n√£o detecta pequenos micr√≥bios.

* Colete em $u_i$ todos os fatores n√£o observ√°veis que afetam a probabilidade de $i$ morrer da doen√ßa: se $i$ √© pobre, onde exatamente eles residem, se h√° m√° qualidade do ar nos arredores de $i$ e outras caracter√≠sticas individuais que impactam o resultado (como configura√ß√£o gen√©tica de $i$).


:::{.fragment}
N√≥s podemos escrever:

$$
c_i = \alpha + \delta w_i + u_i
$$
:::


## Fazer o simples √© sempre certo?

* John Snow poderia ter usado seus dados e avaliar a correla√ß√£o entre beber √°gua impura e a incid√™ncia de c√≥lera.

* medida $Cor(c_i,w_i)$

* Suponha $Cor(c_i,w_i) \approx 0,5$. Isso prova a teoria da infec√ß√£o?


- :warning: N√£o √© bem assim. Angus Deaton disse:

:::{.fragment}
> As pessoas que bebiam √°gua impura tamb√©m eram mais propensas a serem pobres e a viver em um ambiente contaminado de v√°rias maneiras, principalmente pelos ‚Äúmiasmas venenosos‚Äù que eram ent√£o considerados a causa da c√≥lera.
:::


## A coisa simples


* N√£o faz sentido comparar algu√©m que bebe √°gua pura com algu√©m que bebe √°gua impura.

* porque *tudo o mais n√£o √© igual*: a √°gua impura est√° correlacionada com ser pobre, morar em √°rea ruim, m√° qualidade do ar e assim por diante - todos os fatores que encontramos em $u_i$.

* Isso viola a suposi√ß√£o crucial de ortogonalidade para estimativas MQO v√°lidas, $E[u_i | w_i]=0$ neste contexto.

* Outra maneira de dizer isso √© que $Cov(w_i, u_i) \neq 0$, implicando que $w_i$ √© ***end√≥geno***.

* Existem fatores em $u_i$ que afetam tanto $w_i$ quanto $c_i$



## Modelo de Snow e um pouco de √°lgebra

Lembre-se do nosso modelo simples:
$$c_i = \alpha + \delta w_i + u_i$$

- Agora vamos condicionar os dois valores de $w$:
\begin{align}
E[c_i | w_i = 1] &= \alpha + \delta + E[u_i | w_i = 1] \\
E[c_i | w_i = 0] &= \alpha + \phantom{\delta} + E[u_i | w_i = 0]
\end{align}



- Agora subtraia uma linha da outra:
\begin{equation}
E[c_i | w_i = 1] - E[c_i | w_i = 0] = \delta + \left\{ E[u_i | w_i = 1] - E[u_i | w_i = 0]\right\}
\end{equation}

- O √∫ltimo termo $\left\{ E[u_i | w_i = 1] - E[u_i | w_i = 0]\right\}$ n√£o √© igual a zero (pelo que Deaton disse!)

- Uma estimativa de regress√£o para $\delta$ seria influenciada por essa quantidade.



## Estimador de Vari√°veis Instrumentais


* Snow prop√µe uma **vari√°vel instrumental** $z_i$, a *identidade da empresa fornecedora de √°gua* para o domic√≠lio $i$:

- Mais formalmente, vamos definir o instrumento da seguinte forma:

:::{.fragment}
\begin{align*}
z_i &= \begin{cases}
                     1 & \text{se √°gua fornecida por Lambeth} \\
                     0 & \text{se √°gua fornecida por Southwark ou Vauxhall.} \\
       \end{cases} \\
\end{align*}
:::

* $z_i$ est√° altamente correlacionado com a pureza da √°gua $w_i$.

* No entanto, parece n√£o ter correla√ß√£o com todos os outros fatores em $u_i$, que nos preocupavam antes: o abastecimento de √°gua foi decidido anos antes, e agora as casas na mesma rua t√™m fornecedores diferentes!

## VI em um DAG

![](img/IV-dag.png)


## Definindo a VI de Snow formalmente


Aqui est√£o as ***condi√ß√µes para um instrumento v√°lido***:

1. **Relev√¢ncia**: A pureza da √°gua √©, de fato, uma fun√ß√£o da identidade do fornecedor. Queremos que $E[w_i | z_i = 1] \neq E[w_i | z_i = 0]$, ou seja, a pureza m√©dia da √°gua difere entre os fornecedores. Podemos *verificar* esta condi√ß√£o com dados observacionais. 


2. **Independ√™ncia**: Se uma fam√≠lia tem $z_i = 1$ ou $z_i = 0$ n√£o tem rela√ß√£o com $u$, portanto $z$ √© *t√£o bom quanto aleat√≥rio*. Se condicionarmos $u$ a certos valores de $z$ n√£o altera o resultado - queremos $E[u_i | z_i = 1] = E[u_i | z_i = 0].$


3. **Exclusividade** o instrumento deve afetar o resultado $c$ *somente* atrav√©s do canal especificado (ou seja, atrav√©s da pureza da √°gua $w$), e nada mais.


## Definindo o estimador de VI

- Agora estamos prontos para definir um estimador de VI simples. Como antes, vamos condicionar os valores de $z$:
\begin{align}
E[c_i | z_i = 1] &= \alpha + \delta E[w_i | z_i = 1] + E[u_i | z_i = 1] \\
E[c_i | z_i = 0] &= \alpha + \delta E[w_i | z_i = 0] + E[u_i | z_i = 0]
\end{align}

- tomando a diferen√ßa entre as express√µes:
\begin{align}
E[c_i | z_i = 1] - E[c_i | z_i = 0] &= \delta \left\{ E[w_i | z_i = 1] - E[w_i | z_i = 0]\right\} \\
&+ \underbrace{\left\{ E[u_i | z_i = 1] - E[u_i | z_i = 0] \right\}}_{=0 \text{ por Indeped√™ncia}}
\end{align}


- Finalmente, se a VI for *relevante*, ou seja, $E[w_i | z_i = 1] - E[w_i | z_i = 0] \neq 0$:
\begin{equation}
\delta = \frac{E[c_i | z_i = 1] - E[c_i | z_i = 0]}{E[w_i | z_i = 1] - E[w_i | z_i = 0]}
\end{equation}




## Caso Especial: Estimador de Wald 

- Digamos que $x \mapsto y$ significa que $x$ √© uma estimativa para $y$:

    1. $\overline{c}_1 \mapsto E[c_i | z_i = 1]$: a propor√ß√£o de domic√≠lios abastecidos por Lambeth com c√≥lera.
    1. $\overline{w}_1 \mapsto E[w_i | z_i = 1]$: a propor√ß√£o de domic√≠lios abastecidos por Lambeth com √°gua ruim.
    1. $\overline{c}_0 \mapsto E[c_i | z_i = 0]$: a propor√ß√£o de domic√≠lios n√£o abastecidos por Lambeth com c√≥lera.
    1. $\overline{w}_0 \mapsto E[w_i | z_i = 0]$: a propor√ß√£o de domic√≠lios n√£o abastecidos por Lambeth com √°gua ruim.

- O estimador seria ent√£o
\begin{equation}
\hat{\delta} = \frac{\overline{c}_1 - \overline{c}_0}{\overline{w}_1 - \overline{w}_0} 
\end{equation}

- Neste caso especial onde todas as vari√°veis envolvidas $c,w,z$ s√£o bin√°rias, o estimador √© chamado de ***estimador de Wald***.

## Resumo

- VIs s√£o uma ferramenta poderosa para estabelecer causalidade em contextos apenas com dados observacionais e onde estamos preocupados que a suposi√ß√£o de m√©dia condicional $E[u_i | x_i]=0$ √© violado (*endogeneidade*). 

- As principais caracter√≠sticas da VI $z$ s√£o que:

    1. $z$ √© *relevante* para $x$. Por exemplo, em uma regress√£o simples de $z$ em $x$, queremos que $z$ tenha um poder preditivo consider√°vel. Podemos *testar* essa condi√ß√£o nos dados.

    1. Precisamos de uma teoria segundo a qual seja *razo√°vel* supor que $z$ n√£o esteja *relacionado* a outros fatores n√£o observ√°veis que possam impactar o resultado. Portanto, $z$ √© *ex√≥geno* a $u$, ou $E[u | z] = 0$. Esta √© uma **suposi√ß√£o** (ou seja, n√£o podemos testar isso com dados).


## Aplica√ß√µes de Vari√°veis Instrumentais 

- O que fizemos na aula passada?

    + Aprendemos sobre o grande experimento de John Snow em Londres em 1850.

    + Usamos sua hist√≥ria para motivar o estimador IV.

- Hoje

    * Veremos outras aplica√ß√µes IV.

    * Introduzimos uma extens√£o chamada ***M√≠nimos Quadrados em 2 Est√°gios***.

    * Usaremos `Python` para calcular as estimativas.

    * Finalmente falaremos sobre instrumentos *fracos*.



## Retornos da Escolaridade

::::{.columns}
:::{.column width="50%"}

* Qual √© o impacto causal da escolaridade sobre os rendimentos?

* [Jacob Mincer](https://en.wikipedia.org/wiki/Jacob_Mincer) estava interessado nesta importante quest√£o.

* Aqui est√° o modelo dele:
$$
\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + e_i
$$
:::


:::{.column width="50%"}
![](img/schooling-dag.png)

:::
::::


## Retornos da Escolaridade

::::{.columns}
:::{.column width="50%"}
$$
\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + e_i
$$

* Ele encontrou uma estimativa para $\rho$ de cerca de 0,11,

* 11% de vantagem nos ganhos para cada ano adicional de educa√ß√£o

* Veja o DAG. Esse √© um bom modelo? Bem, por que n√£o seria?
:::


:::{.column width="50%"}
![](img/schooling-dag.png)
:::

::::

## Vi√©s de Habilidade

::::{.columns}
:::{.column width="50%"}
* Comparamos os ganhos de homens com certa escolaridade e experi√™ncia de trabalho

* Tudo o mais √© igual, depois de controlar isso?

* Dado $X$,
     * Podemos encontrar trabalhadores mais ou menos diligentes por a√≠?
     * Podemos encontrar trabalhadores com capacidades diferentes?
     * As conex√µes familiares dos trabalhadores variam?
:::



:::{.column width="50%"}
* Sim claro. Ent√£o, *todo o resto* n√£o √© igual.

* Isso √© um problema, porque para consist√™ncia dos MQO exigimos a suposi√ß√£o de ortogonalidade
$$E[e_i | S_i, X_i] = 0$$

* Vamos introduzir a **habilidade** $A_i$ explicitamente.
:::
::::



## Mincer com Habilidade n√£o Observada

::::{.columns}
:::{.column width="50%"}
* Na verdade temos *dois* fatores n√£o-observ√°veis: $e$ e $A$.

* Claro que n√£o podemos distingui-los.

* Ent√£o definimos um novo fator n√£o observ√°vel
$$u_i = e_i + A_i$$

:::


:::{.column width="50%"}

![](img/schooling-dag2.png)
:::

::::

## Mincer com Habilidade n√£o Observada

::::{.columns}
:::{.column width="50%"}
* Em termos de uma equa√ß√£o:
$$\log Y_i = \alpha + \rho S_i + \beta_1 X_i + \beta_2 X_i^2 + \underbrace{u_i}_{A_i + e_i}$$

* √Äs vezes, isso n√£o importa e o vi√©s dos MQO √© pequeno.

* √Äs vezes importa, e a estima√ß√£o √© totalmente errada!
:::


:::{.column width="50%"}

![](img/schooling-dag2.png)
:::
::::


# Mec√¢nica das Vari√°veis Instrumentais

## Identifica√ß√£o

Vamos voltar ao nosso modelo linear simples:

$$
y = \beta_0 + \beta_1 x + u
$$

onde tememos que $Cov(x,u) \neq 0$, $x$ seja *end√≥geno*.

## Condi√ß√µes para VI

1. **Relev√¢ncia do Instrumento**: $Cov(z,x) \neq 0$
1. **Exogenidade do VI** (restri√ß√£o de exclus√£o): $Cov(z,u) = 0$, a VI √© ex√≥gena na equa√ß√£o do resultado.




## Modelo V√°lido (A) vs Modelo Inv√°lido (B) para VI `z`

::::{.columns}
:::{.column width="50%"}

```{python}
# Define the graph
G1 = nx.DiGraph()

# Add nodes
G1.add_nodes_from(["z", "x", "u", "y"])

# Add edges
G1.add_edges_from([("z", "x"), ("x", "y"), ("u", "x"), ("u", "y")])

# Set node positions using planar layout
pos = {"z": (0, 0), "x": (1, 0), "u": (2, 1), "y": (3, 0)}


nx.draw(
    G1,
    pos,
    with_labels=True,
    node_color=["green", "green", "grey", "green"],
    node_size=5000,
    font_size=12,
    edge_color="black",
    linewidths=2,
    width=2,
)
ax = plt.gca()
ax.margins(0.20)
plt.title("(A)")
plt.show()
```

:::

:::{.column width="50%"}

```{python}
# Define the graph
G2 = nx.DiGraph()

# Add nodes
G2.add_nodes_from(["z", "x", "u", "y"])

# Add edges
G2.add_edges_from([("z", "x"), ("u", "z"), ("x", "y"), ("u", "x"), ("u", "y")])

# Set node positions using planar layout
pos = {"z": (0, 0), "x": (1, 0), "u": (2, 1), "y": (3, 0)}


nx.draw(
    G2,
    pos,
    with_labels=True,
    node_color=["green", "green", "grey", "green"],
    node_size=5000,
    font_size=12,
    edge_color="black",
    linewidths=2,
    width=2,
)
ax = plt.gca()
ax.margins(0.20)
plt.title("(B)")
plt.show()
```

:::
::::


## Identifica√ß√£o

::::{.columns}
:::{.column width="50%"}

**Condi√ß√µes para VI**

1. **Relev√¢ncia**: $Cov(z,x) \neq 0$
2. **Exogeneidade**: $Cov(z,u) = 0$

:::

:::{.column width="50%"}

* Como isto ***identifica*** $\beta_1$?

* Como podemos expressar $\beta_1$ em termos de momentos populacionais de forma √∫nica?

:::

::::

## Identifica√ß√£o

$$
\begin{aligned}
Cov(z,y) &= Cov(z, \beta_0 + \beta_1 x + u) \\
         &= \beta_1 Cov(z,x) + Cov(z,u) 
\end{aligned}
$$

::::{.columns}
:::{.column width="50%"}
Sob a condi√ß√£o 2. acima (**restri√ß√£o de exclus√£o**), temos que $Cov(z,u)=0$, ent√£o:

$$
Cov(z,y) = \beta_1 Cov(z,x) 
$$
:::



:::{.column width="50%"}
e sob a condi√ß√£o 1. (**relev√¢ncia**), temos $Cov(z,x)\neq 0$, portanto:

$$
\beta_1 =  \frac{Cov(z,y)}{Cov(z,x)}.
$$

:::
::::

* $\beta_1$ √© ***identificado*** via os momentos populacionais $Cov(z,y)$ e $Cov(z,x)$ 

* Podemos ***estimar*** estes momentos atrav√©s dos ***an√°logos amostrais*** (_sample plugin estimator_)



## Estimador de Vari√°veis Instrumentais

Basta "plugar" os momentos **amostrais**:

$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (z_i - \bar{z})(y_i - \bar{y})}{\sum_{i=1}^n (z_i - \bar{z})(x_i - \bar{x})}$$

* A estimativa do intercepto √© $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$ 



* Dado que ambas as hip√≥teses 1. e 2. s√£o satisfeitas, dizemos que ***o estimador de VI √© consistente para $\beta_1$*** e escrevemos:
$$
\text{plim}(\hat{\beta}_1) = \beta_1
$$

- em palavras: o *limite em probabilidade* de $\hat{\beta}_1$ √© o verdadeiro $\beta_1$. O estimador $\hat{\beta}_1$ converge em probabilidade para o par√¢metro populacional

- Se isso for verdade, dizemos que este estimador √© **consistente**.


## Infer√™ncia com Vari√°veis Instrumentais

Assumindo $E(u^2|x,z) = \sigma^2$ a vari√¢ncia do estimador de VI √©:

$$Var(\hat{\beta}_{1,IV}) = \frac{\sigma^2}{n \sigma_x^2 \rho_{x,z}^2}$$

* $\sigma_x^2$ √© a vari√¢ncia populacional de $x$,

* $\sigma^2$ √© a vari√¢ncia de $u$, e

* $\rho_{x,z}$ √© a correla√ß√£o populacional entre $x$ e $z$.



- Voc√™ pode ver 2 coisas importantes aqui:

  1. Sem o termo $\rho_{x,z}^2$, isso √© **a vari√¢ncia do MQO**.
  2. A medida que o tamanho da amostra $n$ aumenta, a **vari√¢ncia diminui** (assim como no MQO).


## Vari√¢ncia de VI √© sempre maior que MQO

Compare as vari√¢ncias de MQO e VI:


::::{.columns}

:::{.column width="50%"}
- $Var(\hat{\beta}_{1}) = \frac{\sigma^2}{n \sigma_x^2}$
:::

:::{.column width="50%"}
- $Var(\hat{\beta}_{1,IV}) = \frac{\sigma^2}{n \sigma_x^2 \rho_{x,z}^2}$
:::

::::

1. Dado $\rho_{x,z}^2 < 1$ na maioria das situa√ß√µes da vida real, temos que $Var(\hat{\beta}_{1,IV}) > Var(\hat{\beta}_ {1})$ quase certamente.


1. Quanto maior a correla√ß√£o entre $z$ e $x$, mais pr√≥ximo o $\rho_{x,z}^2$ est√° de 1 e voltamos a vari√¢ncia do MQO.



## Vari√¢ncia de VI √© sempre maior que MQO

<img align="center" src="https://media.giphy.com/media/Xg4Lc2tzOXXdNCU4Qc/giphy.gif" width="90"> 

Se tiverermos um regressor ex√≥geno v√°lido $x$, **n√£o** devemos usar VI $z$ para obter $\hat{\beta}$, pois sua vari√¢ncia ser√° desnecessariamente grande.


## Estimador de vari√¢ncia com VI

Novamente utilizamos os an√°logos amostrais

* $n\sigma_x^2$ √© a $SQT_x=\sum_i (x_i - \bar{x})^2$
* $\rho_{x,z}^2$ √© estimado via $R_{x,z}^2$. R2 de uma regress√£o simples de $x$ em $z$
* a vari√¢ncia de $u$ √© obtida atrav√©s do estimador:
$$\hat{\sigma}^2=\frac{1}{n-2}\sum_{i=1}^{n}\hat{u}_i^2$$
onde $\hat{u}_i=y_i-\hat\beta_0-\hat\beta_{1, IV} x_i$

* Portanto, $\widehat{Var}(\hat{\beta}_{1,IV}) = \frac{\hat\sigma^2}{\sum_i (x_i - \bar{x})^2 R_{x,z}^2}$

## Como Saber se a VI √© V√°lida?

Sempre avaliamos uma candidata a VI atrav√©s das 2 condi√ß√µes:

- **Condi√ß√µes para VI**

    1. **Relev√¢ncia**: $Cov(z,x) \neq 0$
    2. **Exclus√£o**: $Cov(z,u) = 0$


* Somente a condi√ß√£o **1.** pode ser testada empiricamente!

* :warning: Restri√ß√£o de exclus√£o √© hip√≥tese n√£o test√°vel
    + Pesquisador deve se valer de teoria econ√¥mica e argui√ß√£o l√≥gica


## M√≠nimos Quadrados em 2 Est√°gios: MQ2E

- **Equa√ß√£o estrutural**: $y_i=\beta_0+\beta_1 s_i + \beta_2 x_i + u_i$


1. Estimamos um **modelo de primeiro est√°gio** que usa apenas vari√°veis ex√≥genas (como $z$) para explicar nosso regressor end√≥geno $s$.

2. Em seguida, usamos a **previs√£o** do 1¬∫ est√°gio, $\hat{s}$, no que √© chamado de modelo de **segundo est√°gio**. Esse procedimento deve eliminar qualquer endogeneidade entre $\hat{s}$ e $y$.

:::{.fragment}
$$
\begin{aligned}
\text{1. Est√°gio: }s_i &= \alpha_0 + \alpha_1 z_i + \alpha_2 x_i + \eta_i \\
\text{2. Est√°gio: }y_i &= \beta_0 + \beta_1 \hat{s}_i + \beta_2 x_i + \varepsilon_i
\end{aligned}
$$

:::

- **Condi√ß√µes:**

  1. Relev√¢ncia do IV: $\alpha_1 \neq 0$
  1. Exogeneidade (restri√ß√£o de exclus√£o): $E[u | z] = 0$


## M√≠nimos Quadrados em 2 Est√°gios: MQ2E

- O primeiro est√°gio isola a endogeneidade no termo de erro $\eta_i$
$$s_i=\underbrace{\alpha_0 + \alpha_1 z_i + \alpha_2 x_i}_{\hat{s}_i\text{: parte ex√≥gena}} + \eta_i$$

- E utiliza somente a parte ex√≥gena no segundo est√°gio!
$$y_i = \beta_0 + \beta_1 \hat{s}_i + \beta_2 x_i + \varepsilon_i$$
Assim o segundo est√°gio faz uso somente de ***varia√ß√µes ex√≥genas*** de $s_i$ e, portanto, $\hat{\beta}_1$ ser√° n√£o viesado.


- :warning: o primeiro est√°gio **DEVE** ser linear. Caso contr√°rio, regress√£o proibida de Hausman! (MHE ch. 4, p. 142)

- N√£o realizamos manualmente porque os erros padr√£o no 2¬∫ est√°gio estar√£o errados


:::{.fragment}
<center>**Vejamos em um exemplo**</center>
:::

## Vamos implementar Angrist e Krueger (1991)! 

### Data de nascimento √© t√£o boa quanto aleat√≥ria


::::{.columns}
:::{.column width="50%"}
* Angrist e Krueger (AK91) √© um estudo influente que aborda o vi√©s de habilidade

     1. construir uma VI que codifique a *data de nascimento do aluno*
     1. A crian√ßa nascida logo ap√≥s a data limite come√ßar√° a escola mais tarde!
    
* Crian√ßas que completam 6 anos at√© 31 de dezembro devem se matricular na 1¬™ s√©rie em setembro do mesmo ano
:::

:::{.column width="50%"}
* Nascidos em dezembro de 2016, estar√£o com 5a9m quando come√ßarem a escola

* Nascidos em 1¬∫ de janeiro de 2017 estar√£o com 6a9m quando *estes* entrarem na escola em setembro de 2023

* Podem legalmente abandonar a escola quando fazem 16 anos! Alguns ter√£o mais escolaridade que outros

* VI Dummy para *trimestre de nascimento*: afeta a escolaridade, mas n√£o est√° relacionado a $A$!
:::
::::


## Setup com Vari√°vel Instrumental

::::{.columns}
:::{.column width="50%"}
* *trimestre de nascimento* dummy $z$: afeta a escolaridade, mas n√£o est√° relacionada a $A$!

* Em particular: se nasceu no 4¬∫ trimestre ou n√£o.
:::

:::{.column width="50%"}

:::{.fragment}
![](img/schooling-dag3.png){width=100%}
:::

:::
::::


## Dados sobre anivers√°rio e sal√°rios

Vamos carregar os dados e olhar seu sum√°rio

```{python}
#| echo: true

# Dados baixados de https://www.masteringmetrics.com/resources/
ak91_file = "../../../data/ak91.dta"
ak91 = pd.read_stata(ak91_file)
# Estatisticas descritivas
ak91.describe()
```

## Transforma√ß√µes dos Dados

* Queremos criar  uma _dummy_ `q4` que √© `TRUE` se voc√™ nasceu no 4¬∫ trimestre.

* criar vers√µes `factor` de trimestre e ano de nascimento.

```{python}
#| echo: true
ak91['qob_fct'] = ak91['qob'].astype('category')
ak91['q4'] = (ak91['qob'] == 4.0).astype(int)
ak91['yob_fct'] = ak91['yob'].astype('category')

ak91_age = ak91.groupby(['qob', 'yob']).agg(lnw=('lnw', 'mean'), s=('s', 'mean')).reset_index()
ak91_age['q4'] = (ak91_age['qob'] == 4)
```


## Primeiro Est√°gio!

Vamos reproduzir agora a primeira figura de AK91 sobre educa√ß√£o em fun√ß√£o do trimestre de nascimento!


::::{.columns}
:::{.column width="30%"}

1. Os n√∫meros rotulados significam trimestre de nascimento.

1. Nascidos no 4¬∫ trimestre **obtiveram** mais educa√ß√£o na maioria dos anos!

1. **Relev√¢ncia da VI**.
:::

:::{.column width="70%"}

```{python}
#| echo: true
fig, ax = plt.subplots(figsize=(14,8))

ak91_age['yob_qob'] = ak91_age['yob'] + (ak91_age['qob'] - 1) / 4
sort_df = ak91_age.sort_values('yob_qob')

ax.plot(sort_df['yob_qob'], sort_df['s'])

for i, txt in enumerate(sort_df['qob'].astype('int')):
    ax.annotate(txt, (sort_df['yob_qob'].iloc[i], sort_df['s'].iloc[i]), 
    fontsize=20,
    bbox=dict(boxstyle='round,pad=0.2', 
    fc=sort_df['q4'].map({False: 'yellow', True: 'purple'}).iloc[i], 
    alpha=0.8))

ax.grid(True)
ax.set_xlabel('Ano de Nascimento')
ax.set_ylabel('Anos de Escolaridade')
plt.show()
```
:::

::::


## Impacto da VI no resultado

E quanto aos sal√°rios para esses grupos?

::::{.columns}
:::{.column width="30%"}

1. Nascidos no 4¬∫ trimestre est√£o entre os mais bem pagos por ano de nascimento.

1. Em geral, os sal√°rios semanais parecem diminuir um pouco ao longo do tempo.

1. Visualiza√ß√£o da **forma reduzida**
:::

:::{.column width="70%"}

```{python}
#| echo: true
fig, ax = plt.subplots(figsize=(14,8))

ax.plot(sort_df['yob_qob'], sort_df['lnw'])

for i, txt in enumerate(sort_df['qob'].astype('int')):
    ax.annotate(txt, (sort_df['yob_qob'].iloc[i], sort_df['lnw'].iloc[i]), 
    fontsize=20,
    bbox=dict(boxstyle='round,pad=0.2', 
    fc=sort_df['q4'].map({False: 'yellow', True: 'purple'}).iloc[i], 
    alpha=0.8))

ax.grid(True)
ax.set_xlabel('Ano de Nascimento')
ax.set_ylabel('Log Sal√°rio Semanal')
plt.show()
```

:::
::::


<!-- ## Executando estimativa VI no `R`

<br>
<br>

::::{.columns}
:::{.column width="50%"}
* V√°rias op√ß√µes (como sempre com `R`! üòâ)

* Usaremos a fun√ß√£o [`iv_robust`](https://declaredesign.org/r/estimatr/reference/iv_robust.html) do pacote `estimatr`.

* *Robusto*? Calcula erros padr√£o que est√£o corrigindo a heterocedasticidade. [Detalhes aqui.](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html)
:::

:::{.column width="50%"}

```{r mq2e, cache=TRUE}
library(estimatr)
# create a list of models
mod <- list()

# standard (biased!) OLS
mod$ols <- lm(lnw ~ s, data = ak91)

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
mod$stage_1 <- lm(s ~ q4, data = ak91)
ak91$shat <- predict(mod$stage_1)  
mod$stage_2 <- lm(lnw ~ shat, data = ak91)

# run 2SLS
# doing IV all in one go
# notice the formula!
# formula = y ~ x | z
mod$MQ2E  <- iv_robust(lnw ~ s | q4,
                       data = ak91,
                       diagnostics = TRUE)
```

:::
:::: -->

## Executando estimativa VI no `Python`

::::{.columns}
:::{.column width="50%"}
* A melhor biblioteca para implementar estimativas de VI no `Python` √© o [`linearmodels`](https://bashtage.github.io/linearmodels/).

* Usaremos a fun√ß√£o `IV2SLS` que inclui a sintaxe de formula, tamb√©m usada no [`statsmodels`](https://www.statsmodels.org/stable/index.html)

* *Robusto*? Calcula **por padr√£o** erros corrigidos para heterocedasticidade. Argumento `cov_type`. @sec-robust
:::

:::{.column width="50%"}

```{python}
#| echo: true

import linearmodels.iv as iv

# Standard (biased!) OLS
ols = iv.IV2SLS.from_formula('lnw ~ 1+s', data=ak91).fit()

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
stage_1 = iv.IV2SLS.from_formula('s ~ 1+q4', data = ak91).fit()
ak91['shat'] = stage_1.predict()  
stage_2 = iv.IV2SLS.from_formula('lnw ~ 1+shat', data = ak91).fit()

# Run 2SLS. Doing IV all in one go
# Notice the formula y ~ [x ~ z]
MQ2E = iv.IV2SLS.from_formula('lnw ~ 1 + [s ~ q4]', data = ak91).fit()
```

:::
::::

<!-- ## Executando estimativa VI no `R`

<br>
<br>

::::{.columns}
:::{.column width="50%"}
* V√°rias op√ß√µes (como sempre com `R`! üòâ)

* Usar√° a fun√ß√£o [`iv_robust`](https://declaredesign.org/r/estimatr/reference/iv_robust.html) do pacote `estimatr`.

* *Robusto*? Calcula erros padr√£o que est√£o corrigindo a heterocedasticidade. [Detalhes aqui.](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html)

* Observe o `predict` para obter $\hat{s}$.
:::


:::{.column width="50%"}

```{r, eval = FALSE}
library(estimatr)
# create a list of models
mod <- list()

# standard (biased!) OLS
mod$ols <- lm(lnw ~ s, data = ak91)

# IV: born in q4 is TRUE?
# doing IV manually in 2 stages.
mod$stage_1 <- lm(s ~ q4, data = ak91)
ak91$shat <- predict(mod$stage_1) #<<
modmod$stage_2 <- lm(lnw ~ shat, data = ak91)

# run 2SLS
# doing IV all in one go
# notice the formula!
# formula = y ~ x | z
mod$MQ2E  <- iv_robust(lnw ~ s | q4,
                       data = ak91,
                       diagnostics = TRUE)
```

:::
::::
 -->

## Resultados

::::{.columns}
:::{.column width="70%"}

<!-- ```{r ms1, echo = FALSE}
glance_custom.iv_robust <- function(x){
  f = x$diagnostic_first_stage_fstatistic
  if (is.null(f)) {
    return()
  } else {
    out <- tibble::tibble(`1. Stage F:` = f["value"])
    return(out)
  }
}
library(huxtable)
tab = msummary(models = mod,
               stars = TRUE,
               statistic = 'std.error',
               gof_omit = 'DF|Deviance|AIC|BIC|R2 Adj.|p.value|F$|se_type|statistic|Log.Lik.|Num.Obs.|N',
               output = "huxtable"
)
tab %>%
  set_bottom_border(row = 9, col = everywhere) %>%
  set_tb_padding(3.5)
``` -->

```{python}
from io import StringIO
import warnings

def compare_df(x, fit_stats=['Estimator', 'R-squared', 'No. Observations'], params_slice=slice(11, None)):
    with warnings.catch_warnings():
        warnings.simplefilter(action='ignore', category=FutureWarning)
        y = pd.read_csv(StringIO(iv.results.compare(x, stars=True, precision='std_errors').summary.as_csv()), skiprows=1, skipfooter=1, engine='python')
    z = pd.DataFrame(
        data=y.iloc[:, 1:].values,
        index=y.iloc[:, 0].str.strip(),
        columns=pd.MultiIndex.from_arrays(
            arrays=[y.columns[1:], y.iloc[0][1:]],
            names=['Model', 'Dep. Var.']
        )
    )
    return pd.concat([z.iloc[params_slice], z.loc[fit_stats]])
```

```{python}
df = compare_df(
  {'OLS': ols, 'Stage 1': stage_1, 'Stage 2': stage_2, 'MQ2E': MQ2E})

# style df to print in small font
df.style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```

:::

:::{.column width="30%"}

1. MQO viesado para baixo (erro de medi√ß√£o)

1. Primeiro Est√°gio: VI `q4` √© estatisticamente significativo

1. O segundo est√°gio tem a mesma estimativa pontual que `MQ2E`, mas um erro padr√£o diferente (segundo est√°gio est√° errado)
:::
::::


## Lembra da estat√≠stica F?

* Encontramos isso antes: √© √∫til testar modelos restritos versus irrestritos entre si.


* Aqui, estamos interessados em saber se nossos instrumentos s√£o *conjuntamente* significativos. Claro, com apenas uma VI, isso n√£o √© mais informativo do que o t-stat dessa VI.


* Este F-Stat compara o poder preditivo do primeiro est√°gio com e sem as VIs. Se eles tiverem poder preditivo muito semelhante, o F-stat ser√° baixo e n√£o poderemos rejeitar H0 de que nossas VIs s√£o **conjuntamente insignificantes** no modelo do primeiro est√°gio. üòû


## VI com um instrumento fraco

* VI √© consistente sob determinadas premissas.

* No entanto, *mesmo* que tenhamos apenas $Cor(z,u)$ muito pequenos, podemos errar

* Pequena correla√ß√£o entre $x$ e $z$ pode produzir estimativas **inconsistentes**.
$$\text{plim}(\hat{\beta}_{1,IV}) = \beta_1 + \frac{Cor(z,u)}{Cor(z,x)} \cdot \frac{\sigma_u}{\sigma_x}$$


* Mesmo que $Cor(z,u)$ seja muito pequena

* Um **instrumento fraco** √© aquele com pequeno valor absoluto para $Cor(z,x)$

* Mesmo com um tamanho de amostra grande, nosso estimador *n√£o* convergir√° para o verdadeiro par√¢metro populacional $\beta_1$.




## VI com um instrumento fraco

Para ilustrar esse ponto, vamos supor que queremos analisar o impacto do n√∫mero de ma√ßos de cigarros fumados por dia por mulheres gr√°vidas (*packs*) no peso ao nascer de seus filhos (*bwght*):

$$\log(bwght) = \beta_0 + \beta_1 packs + u$$

Estamos preocupados que o comportamento de fumar esteja correlacionado com uma s√©rie de outras vari√°veis relacionadas √† sa√∫de que est√£o em $u$ e que podem afetar o peso ao nascer da crian√ßa. 

Ent√£o, procuramos uma **VI**. Suponha que usemos o **pre√ßo dos cigarros** (*cigprice*), supondo que o pre√ßo dos cigarros n√£o esteja correlacionado com fatores em $u$. Vamos executar o primeiro est√°gio de *cigprice* em *packs* e ent√£o vamos mostrar as estimativas de MQ2E:



## VI com um instrumento fraco

<!-- 
```{r bw}
data(bwght, package = "wooldridge")
mods <- list()
mods$Estagio_1 <- lm(packs ~ cigprice, data = bwght)
mods$VI <- estimatr::iv_robust(log(bwght) ~  packs | cigprice, data = bwght, 
                               diagnostics = TRUE)
```

```{r,echo = FALSE}
tbl <- modelsummary(mods, gof_omit = 'DF|Deviance|AIC|BIC|R2 Adj.|p.value|F$|se_type|statistic|Log.Lik.|Num.Obs.|N', output = "huxtable") %>%
    set_bottom_border(row = 7, col = everywhere) %>%
    set_bold(1, everywhere) %>%
    set_tb_padding(5)
font_size(tbl) <- 15
tbl
``` -->

```{python}
#| echo: true
import wooldridge as woo
bwght = woo.dataWoo('bwght')
estagio_1 = iv.IV2SLS.from_formula('packs ~ 1 + cigprice', data = bwght).fit()
vi = iv.IV2SLS.from_formula('np.log(bwght) ~ 1 + [packs ~ cigprice]', data = bwght).fit()
```

```{python}
compare_df({'Est√°gio 1': estagio_1, 'VI': vi}, fit_stats=['Estimator', 'R-squared', 'No. Observations', 'F-statistic']).style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```



## VI com um instrumento fraco

::::{.columns}
:::{.column width="50%"}

* A primeira coluna mostra: primeiro est√°gio muito fraco. *cigprice* parece ter zero impacto na quantidade de ma√ßos consumidos!

* $R^2$ √© zero.

* Por qu√™ usamos esta VI?
:::



:::{.column width="50%"}

* na segunda coluna: impacto muito grande e positivo(!) dos ma√ßos fumados no peso ao nascer. ü§î

* Enorme erro padr√£o.

* Um $R^2$ de -23?!

* F-stat do primeiro est√°gio: 0,121. Corresponde a um valor p de 0.728 : n√≥s **n√£o podemos** rejeitar a H0 de um primeiro est√°gio insignificante.

* Ent√£o: abordagem **inv√°lida**. ‚ùå
:::
::::



## Vari√°veis de Controle Adicionais

* Vimos uma tend√™ncia de tempo clara na educa√ß√£o mais cedo.

* H√° tamb√©m flutua√ß√µes do ciclo de neg√≥cios nos ganhos

* Devemos de alguma forma controlar por diferentes per√≠odos de tempo.

* Al√©m disso, podemos usar mais de uma VI! Aqui est√° como:



## Vari√°veis de Controle Adicionais

<!-- ```{r mq2e2, cache=TRUE}
# we keep adding to our `mod` list:
mod$ols_yr  <- update(mod$ols, . ~ . + yob_fct)  #  previous OLS model

# add exogenous vars on both sides of the `|` !
mod$MQ2E_yr <- iv_robust(lnw ~ s  + yob_fct | q4 + yob_fct, 
                         data = ak91, diagnostics = TRUE ) 

# use all quarters as IVs
mod$MQ2E_all <- iv_robust(lnw ~ s  + yob_fct | qob_fct + yob_fct, 
                          data = ak91, diagnostics = TRUE  )
``` -->

```{python}
#| echo: true
ols_yr = iv.IV2SLS.from_formula('lnw ~ 1+s+yob_fct', data=ak91).fit()
mq2e_yr = iv.IV2SLS.from_formula('lnw ~ 1+yob_fct+[s ~ q4]', data=ak91).fit()
# Use all quarters as IVs
# mq2e_all = iv.IV2SLS.from_formula('lnw ~ 1+yob_fct+[s ~ qob_fct]', data=ak91).fit()
```

## Vari√°veis de Controle Adicionais

<!-- ```{r, echo = FALSE}
# here is how to make the table:
rows <- data.frame(term = c("Instruments","Year of birth"),
                   ols  = c("none","no"),
                   SLS  = c("Q4","no"),
                   ols_yr  = c("none","yes"),
                   SLS_yr  = c("Q4","yes"),
                   SLS_all  = c("All Quarters","yes")
                   )
names(rows)[c(3,5,6)] <- c("2SLS","2SLS_yr","2SLS_all")
tab = msummary(models = mod[c("ols","MQ2E","ols_yr","MQ2E_yr","MQ2E_all")], 
               statistic = 'std.error',
               gof_map = gm,
               add_rows = rows,
               coef_omit = 'yob_fct',
               output = 'huxtable')

htab = tab %>%
  set_bottom_border(row = 6, col = everywhere) %>%
  set_bold(1, everywhere) %>%
  set_tb_padding(4)

htab
``` -->

::::{.columns}
:::{.column width="70%"}


```{python}
compare_df(
  {'OLS': ols, 'MQ2E': MQ2E, 'OLS + Year': ols_yr, 'MQ2E + Year': mq2e_yr}, 
  fit_stats=['Estimator', 'Adj. R-squared', 'No. Observations'],
  params_slice=slice(11,13)).style.set_table_attributes(
    'style="font-size: 18pt; text-align: center"'
)
```
:::

:::{.column width="30%"}
**Adicionando controle de ano**...

* deixa o MQO praticamente inalterado
* ligeiro aumento na estimativa de MQ2E

<!-- **Usando todos os trimestres como VI**...

* Aumenta muito a precis√£o da estimativa MQ2E!
* A estimativa pontual √© de 10,5% agora! -->

:::
::::



## Fazendo um balan√ßo - O Trimestre de Nascimento (QOB)

::::{.columns}
:::{.column width="50%"}
* Isso produzir√° estimativas consistentes se
     1. A VI prediz bem o regressor end√≥geno.
     2. A VI √© t√£o boa quanto aleat√≥ria/independente das VOs.
     3. S√≥ pode impactar o resultado atrav√©s da escolaridade.
    
* Como o QOB se comporta com rela√ß√£o a estes itens?
:::



:::{.column width="50%"}

1. O gr√°fico do 1¬∫ est√°gio e o F-stat alto oferecem evid√™ncias de **relev√¢ncia**. ‚úÖ

2. O QOB √© **independente** de, digamos, *caracter√≠sticas maternas*? Anivers√°rios n√£o s√£o realmente aleat√≥rios - h√° √©pocas de nascimento para certas origens socioecon√¥micas. maior escolaridade materna d√£o √† luz no segundo trimestre. (n√£o no 4¬∫! ‚úÖ)

3. Exclus√£o: E se as crian√ßas mais novas (nascidas no 4¬∫ tri!) forem desfavorecidas desde o in√≠cio, que tem impactos negativos a longo prazo? Ent√£o $E[u|z] \neq 0$! Bem, os mais novos se saem melhor (mais escolaridade e sal√°rio mais alto)! ‚úÖ
:::
::::

# Teorema LATE

## Heterogeneidade e Efeito M√©dio Local

- Suponha que os retornos de escolaridade s√£o heterog√™neos. VI ser√° uma m√©dia destes retornos. Mas **que m√©dia** :question:

- **Efeito M√©dio do Tratamento Local** (local average treatment effect - LATE) √© a m√©dia do efeito do tratamento para os indiv√≠duos que s√£o _"compliers"_ (ou seja, que mudam seu comportamento quando induzidos pelo instrumento).

- Focaremos no caso mais simples: um tratamento bin√°rio e um instrumento bin√°rio. (estimador de Wald para MQ2E)

## Nota√ß√£o de Resultados Potenciais

- Escolaridade para indiv√≠duo $i$ (tratamento) ser√° $D_i = \{0,1\}$. Exemplo, $D_i=1$ se o indiv√≠duo completou o ensino m√©dio.

- Renda √© denotada por $Y_i$.

- Renda **potencial** de $i$ para um n√≠vel de escolaridade $d$ √© $Y_i(d)$.

- Tudo isso j√° sab√≠amos. Mas agora vamos adicionar um **instrumento** $Z_i = \{0,1\}$ que afeta a escolaridade $D_i$.

## Nota√ß√£o de Resultados Potenciais

- Escolarida agora para a ser ***"tratada"*** pelo instrumento $Z_i$. Recebe tamb√©m uma nota√ß√£o potencial.
  + $D_i(Z_i)$

- Renda pode ser indexada como resultado de escolaridade e instrumento.
  + $Y_i(D_i, Z_i)$. Existem 4 poss√≠veis resultados potenciais.

:::{.fragment}
\begin{aligned}
\begin{cases}
Y_i(0,0) & \text{se } D_i=0, Z_i=0 \\
Y_i(1,0) & \text{se } D_i=1, Z_i=0 \\
Y_i(0,1) & \text{se } D_i=0, Z_i=1 \\
Y_i(1,1) & \text{se } D_i=1, Z_i=1 \\
\end{cases}
\end{aligned}
:::

## Hip√≥teses do Teorema LATE

Ser√£o necess√°rias **quatro** hip√≥teses para que o LATE seja identificado:

1. **Independ√™ncia**: $\{Y_i(0, 0), Y_i(1, 0), Y_i(0, 1), Y_i(1, 1), D_i(0), D_i(1)\} \perp Z_i$

2. **Exclus√£o**: $Y_i(d, 0) = Y_i(d, 1)$ para $d\in\{0,1\}$

3. **Relev√¢ncia**: $E[D_i(1)-D_i(0)]\neq 0$

4. **Monotonicidade**: $D_i(1)\geq D_i(0)$, para todo $i$

- Destas, somente a hip√≥tese **4** √© nova.
  + Na pr√°tica ela exclui a presen√ßa de ***desafiantes*** (_defiers_) na popula√ß√£o.

## Status de _Compliance_ do Instrumento

- Dado que o instrumento assume um valor, o efetivo tratamento pode ou n√£o ser influenciado por este instrumento. 

- No caso 2x2 que estamos tratando, existem quatro poss√≠veis status de $D_i(Z_i)$:

:::{.fragment}
\begin{cases}
D_i(0)=D_i(1)=0, \text{ never taker},\\
D_i(0)=D_i(1)=1, \text{ always taker},\\
D_i(0)=0, D_i(1)=1, \text{ complier},\\
D_i(0)=1, D_i(1)=0, \text{ defier},
\end{cases}
:::

- Veja que a hip√≥tese de **monotonicidade implica na aus√™ncia de desafiantes** (_defiers_)
  + Para um desafiante, $D_i(1) < D_i(0)$

## Teorema LATE

:::{#thm-late}
## LATE

Sob as hip√≥teses 1-4, o estimador MQ2E √© dado por:

$$
\frac{E[Y_i|Z_i=1]-E[Y_i|Z_i=0]}{E[D_i|Z_i=1]-E[D_i|Z_i=0]}=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]
$$
:::

- O LATE √© a m√©dia do efeito do tratamento para os indiv√≠duos que s√£o _"compliers"_ (ou seja, que mudam seu comportamento quando induzidos pelo instrumento).

:::{.fragment}
:::{.center}
:warning: **M√©todo de VI sob as hip√≥teses 1-4 √© um estimador de LATE**
:::
:::

## Teorema LATE - Prova

:::{.proof}
## Prova
Podemos escrever o numerador como:

$$
\begin{aligned}
E[Y_i|Z_i=1]-E[Y_i|Z_i=0]&=E[Y_i(D_i(1),1)-Y_i(D_i(0),0)]\\
&=\sum_{g\in\{co, nt, at, df\}}E[Y_i(D_i(1),1)-Y_i(D_i(0),0)|G_i=g]\cdot P[G_i=g]\\
\end{aligned}
$$

onde $g$ √© o status de compliance (complier, never taker, always taker, defier).

- O efeito m√©dio para os grupos _"never taker"_ e _"always taker"_ √© zero pela restri√ß√£o de exclus√£o.

- A probabilidade de haver um _"defier"_ √© zero pela hip√≥tese de monotonicidade.

:::{.fragment}
Portanto:

$$E[Y_i|Z_i=1]-E[Y_i|Z_i=0]=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]\cdot P[D_i(1)>D_i(0)]$$
:::

:::

## Teorema LATE - Prova

:::{.proof}
## Prova
Agora, o denominador:

$$
\begin{aligned}
E[D_i|Z_i=1]-E[D_i|Z_i=0]&=E[D_i(1)-D_i(0)]\\
&=P[D_i(1)>D_i(0)].\\
\end{aligned}
$$

:::{.fragment}
Portanto:

$$
\begin{aligned}
\frac{E[Y_i|Z_i=1]-E[Y_i|Z_i=0]}{E[D_i|Z_i=1]-E[D_i|Z_i=0]}&=\frac{E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]\cdot P[D_i(1)>D_i(0)]}{P[D_i(1)>D_i(0)]}\\
\text{LATE}&=E[Y_i(1)-Y_i(0)|D_i(1)>D_i(0)]
\end{aligned}
$$
:::

:::

# T√≥picos Especiais VI

## Experimentos Aleatorizados

* Experimento aleatorizado (RCT ou A/B testing)


* Atribui ind√≠viduos para grupos Controle ou Tratado, mas n√£o obriga


* Existe _noncompliance_. Tratamento efetivo $T_i \neq Z_i$ designa√ß√£o


* **Atribui√ß√£o ao tratamento** $Z_i$ serve como **instrumento** para o efetivo status $T_i$



# T√≥picos Especiais VI

## Experimentos Aleatorizados

* Duas medidas de tratamento
    + Intention-to-treat (**ITT**): forma reduzida $Y_i=\pi Z_i+v_i$
    + Local Average Treatment Effect (**LATE**): vari√°vel instrumental (MQ2E)


* Para validade do experimento, checa-se o balan√ßo de covariadas entre grupo controle e tratamento
* Bom balan√ßo $\implies$ aleatoriza√ß√£o bem feita. (Imbens e Rubin, 2015)



# T√≥picos Especiais VI

## Instrumentos de Bartik

> A ideia por tr√°s de um instrumento de Bartik √© medir varia√ß√µes locais a partir de um choque nacional (regional)



* Tamb√©m conhecidos como ***Shift-Share design***



* Comuns na literatura de com√©rcio internacional (Autor, Dorn, e Hanson, 2013), imigra√ß√£o (Card, 2009) e trabalho (Bound e Holzer, 2000)



* ***Bartik Instruments: What, When, Why, and How***. Goldsmith-Pinkham, et al. (2020)



# T√≥picos Especiais VI

## Instrumentos de Bartik

* Um choque nacional (_**shifter**_), em diferentes ind√∫strias, √© "espalhado" localmente de forma diferente entre as localidades atrav√©s de uma matriz de exposi√ß√µes (_**shares**_)


* Crescimento do sal√°rio em raz√£o do crescimento no emprego, em uma localidade $l$
$$y_l=\rho+\beta_1x_l+\epsilon_l$$

* Crescimento do emprego √© *produto interno* da fra√ß√£o de cada ind√∫stria $k$ no emprego com o crescimento desta ind√∫stria. $x_l=\sum_kz_{lk}g_{lk}$


* Crescimento da ind√∫stria local √© decomposto: $g_{lk}=g_k+\tilde{g}_{lk}$



* O ***Instrumento de Bartik*** √©: $$Z_l=\sum_k z_{lk}g_k$$



## :books: Leitura Recomendada

* WOOLDRIDGE, Jeffrey M. Introdu√ß√£o √† econometria: uma abordagem moderna. S√£o Paulo: Cengage Learning, 2016. Tradu√ß√£o da 4¬™ edi√ß√£o norte-americana por Jos√© Antonio Ferreira. Cap√≠tulo 15.

* GUJARATI, Damodar N.; PORTER, Dawn C. Econometria b√°sica. Porto Alegre: Amgh Editora, 2011. - 5. ed. Cap√≠tulo 17

* ANGRIST, Joshua D.; PISCHKE, J√∂rn-Steffen. Mostly harmless econometrics: An empiricist's companion. Princeton university press, 2009.

* IMBENS, Guido W.; RUBIN, Donald B. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.

* GOLDSMITH-PINKHAM, Paul; SORKIN, Isaac; SWIFT, Henry. Bartik instruments: What, when, why, and how. American Economic Review, v. 110, n. 8, p. 2586-2624, 2020. DOI: [10.1257/aer.20181047](https://doi.org/10.1257/aer.20181047)

* GREWAL, Rajdeep; ORHUN, Yesim. Unpacking the Instrumental Variables Approach. Impact at JMR, Journal of Marketing Research (August 23). Url: [https://www.ama.org/marketing-news/unpacking-the-instrumental-variables-approach/](https://www.ama.org/marketing-news/unpacking-the-instrumental-variables-approach/)

## AT√â A PR√ìXIMA AULA!


:::footer
[1]: Este slides foram baseados nas aulas de econometria da [SciencesPo Department of Economics](https://github.com/ScPoEcon/ScPoEconometrics-Slides)
:::


# Ap√™ndice

## Erros Padr√£o Robustos{#sec-robust}

- Res√≠duos representa a diferen√ßa entre a vari√°vel dependente o a m√©dia estimada.[^1]
$$
\begin{aligned}
y = X\hat\beta + \hat{u}\\
\hat{u} = y ‚àí X\hat{\beta}
\end{aligned}
$$

- Vari√¢ncia de \hat{\beta} depende dos erros.
$$
\begin{aligned}
Var(\hat{\beta}\mid X) &= E[(X'X)^{-1}X'uu'X(X'X)^{-1}\mid X]\\
&= (X'X)^{-1}X'E[uu'\mid X]X(X'X)^{-1}\\
&= (X'X)^{-1}X'\Sigma X(X'X)^{-1}\\
\end{aligned}
$$

- $\Sigma=E[uu'\mid X]$. Uma matriz $n\times n$

[^1]: Nota√ß√£o matricial, y √© um vetor de $n\times 1$, X √© uma matriz $n\times k$, \beta √© um vetor $k\times 1$ e u √© um vetor $n\times 1$.

## Erros Padr√£o Robustos

- Se os erros s√£o **homoced√°sticos**, ent√£o $\Sigma=\sigma^2I_n$ e o estimador de vari√¢ncia do MQO: $\hat{V}^{mqo}(\hat{\beta}\mid X)=\hat\sigma^2(X'X)^{-1}$. 

- Se os erros s√£o **heteroced√°sticos**, o ***estimador de vari√¢ncia*** do MQO √© inconsistente!
  + Veja que o estimador de MQO de $\beta$ ainda √© consistente

- O **estimador de vari√¢ncia robusto** a heterocedasticidade proposto por White √©:
$$
\begin{aligned}
\hat{V}^{rob}(\hat{\beta}\mid X) &= (X'X)^{-1}X'\hat{\Sigma}X(X'X)^{-1}\\
\hat{\Sigma} &= \begin{bmatrix}
\hat{u}_1^2 & 0 & \cdots & 0\\
0 & \hat{u}_2^2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & \hat{u}_n^2\\
\end{bmatrix}
\end{aligned}
$$
