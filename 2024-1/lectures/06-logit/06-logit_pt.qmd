---
title: "Econometria III"
subtitle: "Modelos de Escolha Qualitativa"
title-slide-attributes:
  data-background-image: "img/UdescEsag.jpeg"
  data-background-size: 50%
  data-background-position: top left
  # data-background-opacity: "0.7"
center-title-slide: true
author: "Rafael Bressan"
logo: "img/UdescEsag.jpeg"
format: 
  revealjs:
    theme: [default, ../udesc.scss] 
    code-fold: true
    chalkboard: true
    incremental: true
    width: 1600
    height: 900
from: markdown+emoji # list of emojis: https://gist.github.com/rxaviers/7360908
fontsize: "2.2em"
# editor: source
engine: jupyter
jupyter: python3
---


```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import wooldridge as woo

import statsmodels.formula.api as smf

from statsmodels.iolib.summary2 import summary_col

# Configure Seaborn
sns.set_style("ticks")
sns.set_context("talk")
```


## Modelos de Escolha Qualitativa

::::{.columns}
:::{.column width="50%"}

At√© agora, nossos modelos ficaram assim:
$$
\begin{align}
y &= b_0 + b_1 x + e \\
e &\sim D\left(0,\sigma^2\right)
\end{align}
$$

* A suposi√ß√£o de distribui√ß√£o em $e$:

* Em princ√≠pio implica que $y \in \mathbb{R}$.

* Resultados de testes, renda, taxas de criminalidade, etc. s√£o todos resultados cont√≠nuos. ‚úÖ
:::



:::{.column width="50%"}

- Mas alguns resultados s√£o claramente bin√°rios (ou seja, `VERDADEIRO` ou `FALSO`):

* Ou voc√™ trabalha ou n√£o,

* Ou voc√™ tem filhos ou n√£o,

* Ou voc√™ comprou um produto ou n√£o,

* Voc√™ jogou uma moeda e saiu cara ou coroa.
:::
::::


## Resultados Bin√°rios

* Resultados restritos a `FALSO` vs `VERDADEIRO`, ou `0` vs `1`.

* Ter√≠amos $y \in \{0,1\}$.

* Nessas situa√ß√µes, estamos principalmente interessados em estimar a **probabilidade de resposta** ou a **probabilidade de sucesso**:

:::{.fragment}
$$p(x) = \Pr(y=1 | x)$$

* como $p(x)$ muda quando mudamos $x$?

     >Se aumentarmos $x$ em uma unidade, como a probabilidade de $y=1$ mudaria?
     
:::

## Lembrando o Experimento de Bernoulli

::::{.columns}
:::{.column width="50%"}
Lembre-se da [Distribui√ß√£o de Bernoulli?](https://en.wikipedia.org/wiki/Bernoulli_distribution): Chamamos uma vari√°vel aleat√≥ria $y \in \{0,1\}$ tal que

$$
\begin{align}
\Pr(y = 1) &= p \\
\Pr(y = 0) &= 1-p \\
p &\in[0,1]
\end{align}
$$

uma vari√°vel aleat√≥ria de *Bernoulli*.
:::



:::{.column width="50%"}
*Condicione* essas probabilidades em uma covariada $x$

$$
\begin{align}
\Pr(y = 1 | X = x) &= p(x) \\
\Pr(y = 0 | X = x) &= 1-p(x) \\
p(x) &\in[0,1]
\end{align}
$$

* Particularmente: *valor esperado* (ou seja, a m√©dia) de $Y$ dado $x$
$$
E[y | x] = 1 \times p(x) + 0 \times (1-p(x)) = p(x)
$$

* Muitas vezes modelamos **expectativas condicionais** üòâ
:::
::::

## O Modelo de Probabilidade Linear (MPL)

* A op√ß√£o mais simples. Modele a probabilidade de resposta como
$$
\Pr(y = 1 | x) = p(x) = \beta_0 + \beta_1 x_1 + \dots + \beta_K x_K
$$

* Interpreta√ß√£o: uma mudan√ßa de 1 unidade em $x_1$, resulta em uma mudan√ßa de $\beta_1$ em $p(x)$.

## Exemplo: Mroz (1987)

* Participa√ß√£o feminina no mercado de trabalho

* Como o status de `inlf` *(na for√ßa de trabalho)* depende da renda familiar da mulher solteira, sua educa√ß√£o, idade e n√∫mero de filhos pequenos?


## Mroz 1987


```{python}
# | echo: true
# | code-fold: show
mroz = woo.dataWoo("mroz")
# Filled histogram. Colors by inlf. Ages in bins of 2 years. Use seaborn
sns.histplot(
    mroz, x="age", hue="inlf", multiple="fill", bins=range(0, 100, 2), stat="density"
)
# Name axes: x = Idade, y = Propor√ß√£o
plt.xlabel("Idade")
plt.ylabel("Propor√ß√£o")
```


## Rodando o MPL

::::{.columns}
:::{.column width="50%"}

```{python}
# | echo: true
# | code-fold: show
lpm = smf.ols(
    "inlf ~ nwifeinc + educ + exper + I(exper**2) + age + I(age**2) + kidslt6",
    data=mroz,
).fit()
df = summary_col([lpm], model_names=["LPM"]).tables[0]
df.iloc[[0, 1, 2, 3, 14, 15, 17], :]
```
:::

:::{.column width="50%"}
* **id√™ntico** aos nossos modelos de regress√£o linear anteriores

* Vari√°vel dependente `inlf` assume somente dois valores, 0 ou 1.

* Resultados: se a renda da mulher solteira aumenta em 10 (ou seja, 10.000 USD), $p(x)$ cai em 0,034 (isso √© um efeito pequeno!),

* uma crian√ßa pequena adicional reduziria a probabilidade de trabalho em 0,26 (isso √© grande).

* At√© agora, tudo simples.Ô∏è
:::
::::


## MPL: Prevendo probabilidades negativas?!


::::{.columns}
:::{.column width="50%"}

```{python}
# | echo: true
# | code-fold: show
pr = lpm.predict()
sns.scatterplot(x=np.arange(len(pr)), y=np.sort(pr))
sns.lineplot(x=[0, len(pr)], y=[0, 0], color="red", linewidth=2)
sns.lineplot(x=[0, len(pr)], y=[1, 1], color="red", linewidth=2)
plt.ylabel("P(inlf = 1)")
plt.xlabel("√çndice")
plt.title("Previs√µes ordenadas do MPL")
```
:::

:::{.column width="50%"}
<br>
<br>
* As previs√µes do MPL de $p(x)$ n√£o est√£o garantidas no intervalo unit√°rio $[0,1]$.

* Lembre-se: $e \sim D\left(0,\sigma^2\right)$

* aqui, algumas probabilidades menores que zero!

* Particularmente irritante se voc√™ quiser *previs√µes*: O que √© probabilidade -0,3? ü§î
:::
::::


## MPL no modelo saturado: sem problemas!

::::{.columns}
:::{.column width="75%"}

```{python}
# | echo: true
# | code-fold: show
mroz["age_fct"] = pd.cut(mroz["age"], bins=3, labels=False)
mroz["huswage_fct"] = pd.cut(mroz["huswage"], bins=2, labels=False)
mroz["classes"] = (
    "age_" + mroz["age_fct"].astype(str) + "_hus_" + mroz["huswage_fct"].astype(str)
)

lpm_saturated = smf.ols("inlf ~ -1 + classes", data=mroz).fit()
lpm_saturated.summary(slim=True).tables[1]
```

:::

:::{.column width="25%"}
* **modelo saturado** : s√≥ tem vari√°veis explicativas bin√°rias (_dummies_)

* Cada classe: $p(x)$ *dentro daquela c√©lula*.

:::
::::



## MPL no modelo saturado: sem problemas!

::::{.columns}
:::{.column width="75%"}

```{python}
lpm_points = lpm_saturated.params
lpm_conf_int = lpm_saturated.conf_int()  # 95%
lpm_df = pd.DataFrame(
    {
        "coef": lpm_points.index.values,
        "est": lpm_points.values,
        "err": lpm_points.values - lpm_conf_int[0],
    }
)
ax = sns.scatterplot(data=lpm_df, x="coef", y="est", hue="coef", legend=False)
ax.errorbar(
    x=lpm_df["coef"],
    y=lpm_df["est"],
    yerr=lpm_df["err"],
    fmt="o",
    color="black",
    capsize=3,
)
ax.hlines([0, 1], -0.5, 5.5, color="red", linestyles="dashed")
# Rotate x-axis labels
plt.xticks(rotation=45, ha="right")
plt.ylabel("Estimativa")
plt.xlabel("Coeficiente")
```
:::

:::{.column width="25%"}

* Cada estimativa pontual: $p(x)$ *dentro do intervalo* $[0,1]$.

* Mulheres da faixa et√°ria mais jovem e de menor renda do marido (coeficiente `age_0_hus_0`) t√™m a maior probabilidade de trabalhar (`{python} lpm_points.iloc[0].round(3)`).
:::
::::


## Modelos de Resposta Bin√°ria N√£o-Lineares

Nesta classe de modelos mudamos a forma como modelamos a probabilidade de resposta $p(x)$. Em vez da estrutura linear simples de cima, escrevemos
$$
\Pr(y = 1 | x) = p(x) = G \left(\beta_0 + \beta_1 x_1 + \dots + \beta_K x_K \right)
$$


* ***quase*** id√™ntico ao MPL!

* exceto que o **√≠ndice linear** $\beta_0 + \beta_1 x_1 + \dots + \beta_K x_K$ agora est√° dentro da ***fun√ß√£o de liga√ß√£o*** $G(\cdot)$ (i.e. _link function_).

* Propriedade principal de $G$: transforma qualquer $z\in \mathbb{R}$ em um n√∫mero no intervalo $(0,1)$.

* Isso resolve nosso problema de previs√µes fora do intervalo $\left[0, 1\right]$ para probabilidades.


## Modelos de Resposta Bin√°ria N√£o-Lineares

### $G$: *probit* e *logit*

::::{.columns}
:::{.column width="75%"}
```{python}
from scipy.stats import norm
from scipy.special import expit

x = np.linspace(-5, 5, 100)

sns.lineplot(x=x, y=norm.cdf(x), color='red', label='Probit')
sns.lineplot(x=x, y=expit(x), color='blue', label='Logit')

plt.xlabel('x')
plt.ylabel('Pr(y = 1 | x)')
plt.legend(title='Fun√ß√£o G')

plt.show()
```
:::

:::{.column width="25%"}

<br>
Para **probit** e **logit**:

1. qualquer valor $x$ resulta em um valor $p(x)$ entre 0 e 1.

1. estritamente crescentes.

1. Logit tem *caudas mais longas*.

:::
::::



## Modelos de Resposta Bin√°ria N√£o-Lineares

### $G$: *probit* e *logit*

::::{.columns}
:::{.column width="70%"}

```{python}
from scipy.stats import norm
from scipy.special import expit

x = np.linspace(-5, 5, 100)

sns.lineplot(x=x, y=norm.cdf(x), color='red', label='Probit')
sns.lineplot(x=x, y=expit(x), color='blue', label='Logit')

plt.xlabel('x')
plt.ylabel('Pr(y = 1 | x)')
plt.legend(title='Fun√ß√£o G')

plt.show()
```
:::

:::{.column width="30%"}

<br>

:::{.fragment}
**Probit**:

$G(z)=\Phi(z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}t^2}dt$ Distribui√ß√£o Normal
:::

:::{.fragment}
**Logit**:

$G(z)=\Lambda(z)=\frac{1}{1+\exp(-z)}$ Distribui√ß√£o Log√≠stica
:::
:::
::::


## Modelos de Resposta Bin√°ria N√£o-Lineares

### Rodando probit e logit no `Python`

* Podemos usar a fun√ß√£o `glm` para rodar um **modelo linear generalizado**

* Isso **generaliza** nosso modelo linear padr√£o. Temos que especificar uma `fam√≠lia` e um `link`.

* Por√©m o `statsmodels` possui fun√ß√µes especializadas para probit e logit.

:::{.fragment}
```{python}
# | echo: true
# | code-fold: show
probit = smf.probit("inlf ~ age", data=mroz).fit()

logit = smf.logit("inlf ~ age", data=mroz).fit()
```

:::

## Interpreta√ß√£o

::::{.columns}
:::{.column width="50%"}

```{python}
summary_col([probit, logit], stars=True, model_names=["Probit", "Logit"])
```
:::

:::{.column width="50%"}
* coeficiente de probit para `idade` √© `{python} probit.params['age'].round(3)`

* `{python} logit.params['age'].round(3)` para logit,

* impacto da idade na probabilidade de trabalhar √© **negativo**

* No entanto, **qu√£o** negativo? N√£o podemos dizer!
:::
::::


## Interpreta√ß√£o

$$
\Pr(y = 1 | \text{age})= G \left(x \beta\right) = G \left(\beta_0 + \beta_1 \text{age} \right) 
$$
e o *efeito marginal* de `idade` na probabilidade de resposta positiva √©

$$\frac{\partial{\Pr(y = 1 | \text{age})}}{ \partial{\text{age}}} = g \left(\beta_0 + \beta_1 \text{age} \right) \beta_1$$

* $g$ √© definida como $g(z) = \frac{dG}{dz}(z)$ - a primeira derivada de $G$ (sendo $G$ uma distribui√ß√£o, $g$ √© a fun√ß√£o densidade).

* dado que $G$ √© n√£o-linear, isso significa que $g$ n√£o ser√° constante. Voc√™ pode experimentar isso usando este [aplicativo aqui](https://floswald.shinyapps.io/marginal_effects_of_logit_probit/):




## Interpreta√ß√£o

***N√£o h√° um √∫nico efeito marginal*** nesses modelos, pois isso depende de *onde avaliamos* a express√£o anterior. Na pr√°tica, existem duas abordagens comuns:

1. reporte o **efeito parcial na m√©dia** (PEA): $$PEA(X_j)=g(\bar{x} \beta) \beta_j$$

1. relate o **efeito parcial m√©dio** (APE): $$APE(X_j)=\frac{1}{n} \sum_{i=1}^N g(x_i \beta) \beta_j$$

:::{.fragment}
Felizmente, a classe dos resultados de um GLM tem um m√©todo [`get_margeff`](https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLMResults.get_margeff.html#statsmodels.genmod.generalized_linear_model.GLMResults.get_margeff) que calcula esses efeitos para n√≥s.
:::


## Efeitos Marginais

```{python}
# | echo: true
# | code-fold: show
def get_mfx(model):
    return pd.concat(
        [
            model.get_margeff(at=p).summary_frame().loc[:, ["dy/dx", "Std. Err."]]
            for p in ["mean", "overall"]
        ],
        axis=1,
    )


f = "inlf ~ age + kidslt6 + nwifeinc"  # Regressao estimada
probit_reg = smf.probit(f, data=mroz).fit()
logit_reg = smf.logit(f, data=mroz).fit()

probit_mfx = get_mfx(probit_reg)
logit_mfx = get_mfx(logit_reg)
```

## Efeitos Marginais

**Probit**
```{python}
# Show PEA and APE. Only the dy/dx and Std. Err. columns
inner_cols = probit_mfx.columns.values
outer_cols = np.array(["PEA", "APE"]).repeat(2)
probit_mfx.columns = pd.MultiIndex.from_arrays([outer_cols, inner_cols])

probit_mfx
```

**Logit**
```{python}
logit_mfx.columns = pd.MultiIndex.from_arrays([outer_cols, inner_cols])

logit_mfx
```



## Qualidade do Ajuste em Modelos Bin√°rios

* N√£o existe $R^2$ universalmente aceito para modelos bin√°rios.

* Podemos pensar em um [*pseudo* $R^2$](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.ProbitResults.html#statsmodels.discrete.discrete_model.ProbitResults) que compara nosso modelo com outro sem regressores:

:::{.fragment}
```{python}
# | echo: true
# | code-fold: show
probit_reg.prsquared
```
:::


* Mas isso n√£o √© super informativo (ao contr√°rio do $R^2$). As altera√ß√µes no valor da log-verossimilhan√ßa s√£o altamente n√£o lineares.


## Qualidade do Ajuste em Modelos Bin√°rios

* Vamos verificar **precis√£o** - qual √© a propor√ß√£o prevista corretamente! 

- Podemos atribuir a previs√£o `1` caso $p(x) > 0.5$ e `0` caso contr√°rio.

:::{.fragment}


```{python}
# | echo: true
# | code-fold: show
confusion_tbl = probit_reg.pred_table(threshold=0.5) / probit_reg.nobs

confusion_matrix = pd.DataFrame(
    confusion_tbl,
    index=["Real 0", "Real 1"],
    columns=["Previsto 0", "Previsto 1"],
)
confusion_matrix
```
:::


## Curvas ROC (Receiver Operating Characteristics)

```{python}
tp = confusion_matrix.loc["Real 1", "Previsto 1"]
fn = confusion_matrix.loc["Real 1", "Previsto 0"]
p = tp + fn
tpr = tp / p
fp = confusion_matrix.loc["Real 0", "Previsto 1"]
tn = confusion_matrix.loc["Real 0", "Previsto 0"]
n = fp + tn
fpr = fp / n
```


[**Nomenclatura**](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

::::{.columns}

:::{.column width="50%"}

**Taxa de Verdadeiros Positivos** (TPR, sensitividade, _recall_): $TP/P=$ `{python} tpr.round(3)`  

**Taxa de Falsos Positivos** (FPR): $FP/N=$ `{python} fpr.round(3)`

**Acur√°cia**: $(TP + TN)/ (P+N)=$ `{python} (tp+tn).round(3)`
:::

:::{.column width="50%"}

:::{.panel-tabset}

## TPR

```{python}
# Make the background of second row, columns 2 and 3 darkgreen
(confusion_matrix.style
  .applymap(
    lambda x: "background-color: darkgreen; color: white" if (x > 0.44) | (x < 0.13) else ""
  )
  .applymap(
    lambda x: "font-weight: bold" if x > 0.44 else "" 
  )
)
```
M√©trica relacionada a **Poder**

## FPR

```{python}
# Make the background of first row, columns 2 and 3 darkgreen
(confusion_matrix.style
  .applymap(
    lambda x: "background-color: darkgreen; color: white" if (x < 0.44) & (x > 0.13) else ""
  )
  .applymap(
    lambda x: "font-weight: bold" if (x > 0.17) & (x < 0.27) else "" 
  )
)
```

M√©trica relacionada a **Erro Tipo I**

## ACC
  
```{python}
# Make the background of main diagonal darkgreen
(confusion_matrix.style
  .applymap(
    lambda x: "background-color: darkgreen; color: white; font-weight: bold" if (x > 0.44) | ((x > 0.13) & (x < 0.17)) else ""
  )
)
```
:::

:::

::::



## Curvas ROC 

* O corte de 0,5 √© arbitr√°rio. E se todas as probabilidades previstas forem $> 0,5$, mas nos dados houver cerca de 50% de zeros?

* Vamos escolher um *corte arbitr√°rio* $c \in (0,1)$ e verificar a precis√£o de cada valor. Isso d√° uma vis√£o melhor.

* Podemos confrontar a **taxa de verdadeiros positivos** (TPR) com a **taxa de falsos positivos** (FPR), para cada valor de corte $c\in[0, 1]$.

     1. TPR: n√∫mero de mulheres corretamente previstas para trabalhar dividido pelo n√∫mero de mulheres que trabalham.
     
     2. FPR: n√∫mero de mulheres incorretamente previstas para trabalhar dividido pelo n√∫mero de mulheres n√£o trabalhadoras.
    
* Plotar ***FPR vs TPR*** para cada $c$ define a curva **ROC**.

* Um bom modelo tem uma curva ROC no canto superior esquerdo: FPR = 0, TPR = 1.


## Curvas ROC 

::::{.columns}
:::{.column width="75%"}

```{python}
# | echo: true
# | code-fold: show
from sklearn.metrics import roc_curve, auc, accuracy_score
pred_prob = probit_reg.predict()
fpr, tpr, thresholds = roc_curve(mroz["inlf"], pred_prob)
roc_auc = auc(fpr, tpr)
accuracies = [accuracy_score(mroz["inlf"], pred_prob > t) for t in thresholds]
acc_t = thresholds[np.argmax(accuracies)] # threshold que maximiza a acur√°cia

plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (area = {roc_auc: .2f})")
plt.legend()
plt.ylabel("TPR")
plt.xlabel("FPR")
```
:::

:::{.column width="25%"}
<br>
<br>

* Melhor precis√£o em torno de $c=`{python} acc_t.round(2)`$

* ROC sempre acima da linha de 45 graus. Melhor do que atribui√ß√£o aleat√≥ria (jogar uma moeda)!

:::
::::


## Estima√ß√£o de M√°xima Verossimilhan√ßa

* Ao inv√©s de usar m√©dia e vari√¢ncia condicionais, usaremos a distribui√ß√£o condicional completa

* Amostra *iid* $\lbrace y_i, x_i \rbrace_{i=1}^N$. Queremos estimar a distribui√ß√£o $f(y|x)$

* **Hip√≥tese:** esta distribui√ß√£o √© conhecida, a n√£o ser por um n√∫mero finito de par√¢metros fixos.
  + Impomos um modelo param√©trico para a densidade condicional
    


## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Probit

::::{.columns}
:::{.column width="50%"}
* $y_i^*=x_i\theta + \varepsilon_i$, sendo $\varepsilon_i\sim N(0,1)$

* N√£o observamos $y_i^*$, apenas $y_i$
:::

:::{.column width="50%"}
:::{.fragment}
$$
\begin{equation*}
y_i = \begin{cases}
1 \text{ se } y_i^* > 0\\ 
0 \text{ se } y_i^* \leq 0
\end{cases}
\end{equation*}
$$
:::
:::
::::


- Dadas as especifica√ß√µes acima:
$$
\begin{aligned}
P(y_i=1|x_i)&=P(y_i* > 0|x_i)\\
&=P(\varepsilon_i > -x_i\theta |x_i)\\
&=1-\Phi(-x_i\theta)\\
&=\Phi(x_i\theta)
\end{aligned}
$$


## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Probit

* A fun√ß√£o de probabilidade condicional pode ser escrita como:
$$p(y_i|x_i)=\Phi(x_i\theta)^{y_i}\cdot [1-\Phi(x_i\theta)]^{1-y_i}$$


* Esta √© a probabilidade de ocorr√™ncia de um ponto $(x_i, y_i)$. Para o conjunto de dados observados temos a ***fun√ß√£o de verossimilhan√ßa***
$$\ell(\theta)=\Pi_{i=1}^N \Phi(x_i\theta)^{y_i}\cdot [1-\Phi(x_i\theta)]^{1-y_i}$$



* M√°xima Verossimilhan√ßa consiste em ***maximizar a fun√ß√£o de verossimilhan√ßa*** em rela√ß√£o aos par√¢metros, $\theta$.

* Podemos maximizar a ***log-verossimilhan√ßa*** por praticidade. $\mathcal{L}(\theta)=\log(\ell(\theta))=\sum_{i=1}^N y_i\log(\Phi(x_i\theta))+(1-y_i)\log(1-\Phi(x_i\theta))$


## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Probit

:::{.fragment}
$$\hat\theta = \arg \max_{\theta} \mathcal{L}(\theta)$$
:::

* O vetor de ***score*** √© dado pela derivada da log-verossimilhan√ßa em rela√ß√£o a cada um dos par√¢metros
$$s(\theta)=\nabla_\theta \mathcal{L}(\theta)=\left[\frac{\partial\mathcal{L}(\theta)}{\partial\theta_1}, \ldots, \frac{\partial\mathcal{L}(\theta)}{\partial\theta_k}\right]^{\prime}$$

* A Hessiana √© a matriz de segundas derivadas
$$H(\theta)=\nabla^2_\theta \mathcal{L}(\theta)$$


## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Probit

Exerc√≠cio: Calcule o _score_ do modelo probit.


## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Probit - Solu√ß√£o

$\mathcal{L}(\theta)=\sum_{i=1}^N y_i\log(\Phi(x_i\theta))+(1-y_i)\log(1-\Phi(x_i\theta))$



$$\begin{align}
s(\theta)&=\frac{d\mathcal{L}(\theta)}{d\theta}=\sum_{i=1}^N y_i x_i\frac{\phi(x_i \theta)}{\Phi(x_i \theta)} - (1-y_i)x_i\frac{\phi(x_i \theta)}{1-\Phi(x_i \theta)}\\
&=\sum_{i=1}^N \frac{[1-\Phi(x_i \theta)]y_i x_i\phi(x_i \theta) - \Phi(x_i \theta)(1-y_i)x_i\phi(x_i \theta)}{\Phi(x_i \theta) [1-\Phi(x_i \theta)]}\\
&=\sum_{i=1}^N \frac{x_i\phi(x_i \theta)}{\Phi(x_i \theta) [1-\Phi(x_i \theta)]}[y_i-\Phi(x_i \theta)]
\end{align}$$



## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Exponencial

- Suponha que tenhamos um conjunto simples de dados $\{x_i\}_{i=1}^N$ $iid$ e queremos ajustar uma distribui√ß√£o exponencial

- $x_i\sim Exp(\lambda)$. $f(x; \lambda)=\frac{1}{\lambda}e^{-x_i/\lambda}$. $x_i\geq 0$.

- Qual √© a fun√ß√£o de log-verossimilhan√ßa?
- Encontre o estimador de m√°xima verossimilhan√ßa $\hat\lambda_{mle}$



## Estima√ß√£o de M√°xima Verossimilhan√ßa

### Exemplo Exponencial

- Fun√ß√£o de verossimilhan√ßa: $L(\lambda)=\Pi_{i=1}^N f(x_i; \lambda)=\Pi_{i=1}^N \frac{1}{\lambda}e^{-x_i/\lambda}$

- Log-verossimilhan√ßa: $\mathcal{L}(\lambda)=\sum_{i=1}^N \log \frac{1}{\lambda}e^{-x_i/\lambda}$


- Ao final encontramos ...

::::{.columns}

:::{.column width="50%"}
:::{.fragment}
$$\hat\lambda_{mle}=\frac{1}{N}\sum_{i=1}^N x_i$$
:::
:::

:::{.column width="50%"}
:::{.fragment}
![](https://media.giphy.com/media/Jlirxn597uSeW7kPAQ/giphy.gif)
:::
:::
::::



## M√©todo dos Momentos Generalizado

### M√©todo dos Momentos (MM)

* Podemos utilizar momentos populacionais para identificar par√¢metros
    + $E[u_i]=0$ √© um exemplo

* De fato, ***tanto MQO quanto VI*** podem ser entendidos como estimadores MM!

* Quais s√£o os momentos utilizados no MQO?


* $E[u]=0$ e $E[xu]=0$, que s√£o as equa√ß√µes normais do MQO

* O MM resolve o an√°logo amostral destas equa√ß√µes


## M√©todo dos Momentos Generalizado

### M√©todo dos Momentos (MM)

::::{.columns}
:::{.column width="75%"}

* Vamos considerar um _setup_ mais geral:
* $\theta_0\in\mathbb{R}^p$ √© um vetor dos par√¢metros da popula√ß√£o
* $m(\theta_0)\equiv E[g(Z_i, \theta_0)]=0$, s√£o as equa√ß√µes de momento
* $g(Z_i, \theta)$ √© uma fun√ß√£o vetorial $r\times 1$
* $Z_i\equiv (X_i, Y_i)$ √© uma observa√ß√£o do conjunto de dados 
* $\theta_0$ √© a √∫nica solu√ß√£o para a equa√ß√£o de momento
* MM vai resolver o an√°logo amostral:

:::{.fragment}
$$\hat{m}(\hat\theta)=\frac{1}{N}\sum_{i=1}^N g(Z_i, \hat\theta)=0$$
:::
:::

:::{.column width="25%"}
:::{.fragment}
![](https://media.giphy.com/media/YmnRIWXjSkct9ZZtNZ/giphy.gif)
:::
:::
::::


## M√©todo dos Momentos Generalizado

### Clarificando

* **Considere o MQO**. Podemos escrever duas equa√ß√£o de momento que identificam os par√¢metros do modelo
$$
\hat{m}(\hat\beta)=\begin{cases}
\frac{1}{N}\sum_{i=1}^N(y_i-\hat\beta_0-\hat\beta_1 x_i)=0\\
\frac{1}{N}\sum_{i=1}^Nx_i(y_i-\hat\beta_0-\hat\beta_1 x_i)=0
\end{cases}
$$

* O MM escreve momentos populacionais em termos dos par√¢metros e resolve o sistema de equa√ß√µes, simples!

## M√©todo dos Momentos Generalizado

### GMM

* Podemos generalizar o m√©todo dos momentos. Da√≠ o nome ***generalized method of moments*** - **GMM**

* Minimizar a norma ${\displaystyle \|{\hat {m}}(\theta )\|_{W}^{2}={\hat {m}}(\theta )^{\mathsf {T}}\,W{\hat {m}}(\theta)}$

* Onde $W$ √© uma matriz positiva definida

* ${\displaystyle {\hat {\theta }}=\operatorname {arg} \min _{\theta \in \Theta }{\bigg (}{\frac {1}{N}}\sum _{i=1}^{N}g(Z_{i},\theta ){\bigg )}^{\mathsf {T}}{W}{\bigg (}{\frac {1}{N}}\sum_{i=1}^{N}g(Z_{i},\theta ){\bigg )}}$


* Especialmente √∫til quando temos mais equa√ß√µes de momento do que par√¢metros


## M√©todo dos Momentos Generalizado

### Aplica√ß√µes de GMM

* MQO, VI e MLE podem ser obtidos a partir de um GMM

* Aplica√ß√µes diversas em
    + _Cross-Section_: modelos n√£o-lineares com vari√°veis end√≥genas 
    + S√©ries Temporais: correla√ß√£o serial e heterocedasticidade
    + Painel: extens√µes do modelo de efeitos fixos

* Veja mais em [Wooldridge (2001) JEP](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.15.4.87)



## :books: Leitura Recomendada

* WOOLDRIDGE, Jeffrey M. Introdu√ß√£o √† econometria: uma abordagem moderna. S√£o Paulo: Cengage Learning, 2016. Tradu√ß√£o da 4¬™ edi√ß√£o norte-americana por Jos√© Antonio Ferreira. Cap√≠tulo 17 Modelo com Vari√°veis Dependentes Limitadas e Corre√ß√µes da Sele√ß√£o Amostral.

* GUJARATI, Damodar N.; PORTER, Dawn C. Econometria b√°sica. Porto Alegre: Amgh Editora, 2011. - 5. ed. Cap√≠tulo 15 Modelos de regress√£o de resposta qualitativa

* WOOLDRIDGE, Jeffrey M. Econometric Analysis of Cross Section and Panel Data. MIT press, 2010. Second Edition. Chapter 15 Binary Response Models



## AT√â A PR√ìXIMA AULA!

<!-- Com a Lista 1 feita! `r emo::ji("white_check_mark")` -->

:::{.footer}
[1]: Este slides foram baseados nas aulas de econometria da [SciencesPo Department of Economics](https://github.com/ScPoEcon/ScPoEconometrics-Slides)
:::

